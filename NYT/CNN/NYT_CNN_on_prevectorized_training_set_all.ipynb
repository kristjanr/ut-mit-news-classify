{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": " NYT-CNN on prevectorized training set all",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COl-b3Cuj_af",
        "outputId": "233ebd58-8057-4501-f70f-7adbe3fe8156"
      },
      "source": [
        "!pip install wandb\n",
        "!wandb login "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/28/4aefc543967839bdb4e139831b82004279f1c435cede2a9557ccf8369875/wandb-0.10.27-py2.py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 8.5MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 51.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/92/5a33be64990ba815364a8f2dd9e6f51de60d23dfddafb4f1fc5577d4dc64/sentry_sdk-1.0.0-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 39.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Collecting pathtools\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 11.6MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (56.0.0)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: pathtools, subprocess32\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=494b25bd82b71f3f79dd55d16ae1c95d4638cea2c9719d2dcd3b916603605a47\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=3cc1c2bf0fab6b5fe94cb0fc600f29752e69cc466ae2ed4d599c08fc40960bcc\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "Successfully built pathtools subprocess32\n",
            "Installing collected packages: shortuuid, smmap, gitdb, GitPython, configparser, sentry-sdk, docker-pycreds, pathtools, subprocess32, wandb\n",
            "Successfully installed GitPython-3.1.14 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 sentry-sdk-1.0.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.10.27\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fgj88POfmDYv",
        "outputId": "3c3907a2-eab2-416d-8c80-15e8508a6cda"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/Colab Notebooks/NLP/project/\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Colab Notebooks/NLP/project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi61aWUbEhcK"
      },
      "source": [
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "import time\n",
        "\n",
        "import wandb\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUSrOjMIJlN4"
      },
      "source": [
        "PAD = '<PAD>'\n",
        "PAD_ID = 0\n",
        "UNK = '<UNK>'\n",
        "UNK_ID = 1\n",
        "VOCAB_PREFIX = [PAD, UNK]\n",
        "\n",
        "VEC_PATH = Path('vector_cache') / 'wiki-news-300d-1M.vec'\n",
        "MAX_VOCAB = 25000\n",
        "\n",
        "batch_size = 64\n",
        "validation_split = .3\n",
        "shuffle_dataset = True\n",
        "random_seed = 42"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJx488cqJlPT"
      },
      "source": [
        "class BaseVocab:\n",
        "    def __init__(self, data, lower=False):\n",
        "        self.data = data\n",
        "        self.lower = lower\n",
        "        self.build_vocab()\n",
        "        \n",
        "    def normalize_unit(self, unit):\n",
        "        if self.lower:\n",
        "            return unit.lower()\n",
        "        else:\n",
        "            return unit\n",
        "        \n",
        "    def unit2id(self, unit):\n",
        "        unit = self.normalize_unit(unit)\n",
        "        if unit in self._unit2id:\n",
        "            return self._unit2id[unit]\n",
        "        else:\n",
        "            return self._unit2id[UNK]\n",
        "    \n",
        "    def id2unit(self, id):\n",
        "        return self._id2unit[id]\n",
        "    \n",
        "    def map(self, units):\n",
        "        return [self.unit2id(unit) for unit in units]\n",
        "        \n",
        "    def build_vocab(self):\n",
        "        NotImplementedError()\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self._unit2id)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY-QgWo9JlTj"
      },
      "source": [
        "class PretrainedWordVocab(BaseVocab):\n",
        "    def build_vocab(self):\n",
        "        self._id2unit = VOCAB_PREFIX + self.data\n",
        "        self._unit2id = {w:i for i, w in enumerate(self._id2unit)}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ar7b46jYJlXC"
      },
      "source": [
        "class LabelVocab(BaseVocab):\n",
        "    def build_vocab(self):\n",
        "        self._id2unit = self.data\n",
        "        self._unit2id = {w:i for i, w in enumerate(self._id2unit)}"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBByipT4L4Kw"
      },
      "source": [
        "class Pretrain:\n",
        "    def __init__(self, vec_filename, max_vocab=-1):\n",
        "        self._vec_filename = vec_filename\n",
        "        self._max_vocab = max_vocab\n",
        "        \n",
        "    @property\n",
        "    def vocab(self):\n",
        "        if not hasattr(self, '_vocab'):\n",
        "            self._vocab, self._emb = self.read()\n",
        "        return self._vocab\n",
        "    \n",
        "    @property\n",
        "    def emb(self):\n",
        "        if not hasattr(self, '_emb'):\n",
        "            self._vocab, self._emb = self.read()\n",
        "        return self._emb\n",
        "        \n",
        "    def read(self):\n",
        "        if self._vec_filename is None:\n",
        "            raise Exception(\"Vector file is not provided.\")\n",
        "        print(f\"Reading pretrained vectors from {self._vec_filename}...\")\n",
        "        \n",
        "        words, emb, failed = self.read_from_file(self._vec_filename, open_func=open)\n",
        "        \n",
        "        if failed > 0: # recover failure\n",
        "            emb = emb[:-failed]\n",
        "        if len(emb) - len(VOCAB_PREFIX) != len(words):\n",
        "            raise Exception(\"Loaded number of vectors does not match number of words.\")\n",
        "            \n",
        "        # Use a fixed vocab size\n",
        "        if self._max_vocab > len(VOCAB_PREFIX) and self._max_vocab < len(words):\n",
        "            words = words[:self._max_vocab - len(VOCAB_PREFIX)]\n",
        "            emb = emb[:self._max_vocab]\n",
        "                \n",
        "        vocab = PretrainedWordVocab(words, lower=True)\n",
        "        print(\"Done Reading\")\n",
        "        \n",
        "        return vocab, emb\n",
        "        \n",
        "    def read_from_file(self, filename, open_func=open):\n",
        "        \"\"\"\n",
        "        Open a vector file using the provided function and read from it.\n",
        "        \"\"\"\n",
        "        first = True\n",
        "        words = []\n",
        "        failed = 0\n",
        "        with open_func(filename, 'rb') as f:\n",
        "            for i, line in enumerate(f):\n",
        "                try:\n",
        "                    line = line.decode()\n",
        "                except UnicodeDecodeError:\n",
        "                    failed += 1\n",
        "                    continue\n",
        "                if first:\n",
        "                    # the first line contains the number of word vectors and the dimensionality\n",
        "                    first = False\n",
        "                    line = line.strip().split(' ')\n",
        "                    rows, cols = [int(x) for x in line]\n",
        "                    emb = np.zeros((rows + len(VOCAB_PREFIX), cols), dtype=np.float32)\n",
        "                    continue\n",
        "\n",
        "                line = line.rstrip().split(' ')\n",
        "                emb[i+len(VOCAB_PREFIX)-1-failed, :] = [float(x) for x in line[-cols:]]\n",
        "                words.append(' '.join(line[:-cols]))\n",
        "        return words, emb, failed"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI3qkifadUn5"
      },
      "source": [
        "def pad_sequences(batch):\n",
        "    max_len = max([len(x[0]) for x in batch])\n",
        "    padded_sequences = torch.zeros((len(batch), max_len), dtype=torch.long)\n",
        "    labels = torch.zeros((len(batch), len(batch[0][1])), dtype=torch.float)\n",
        "    for i, sample in enumerate(batch):\n",
        "\n",
        "      padded_sequences[i, :len(sample[0])] = sample[0]\n",
        "      labels[i, :] = sample[1]\n",
        "\n",
        "    padded_sequences = padded_sequences.to(device)\n",
        "    labels = labels.to(device)\n",
        "    \n",
        "    return padded_sequences, labels\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, pretrain, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
        "                 dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "                \n",
        "        self.embedding = nn.Embedding.from_pretrained(\n",
        "            torch.from_numpy(pretrain.emb), \n",
        "            padding_idx=pad_idx, \n",
        "            freeze=True\n",
        "        )\n",
        "        \n",
        "        self.convs = nn.ModuleList([\n",
        "                                    nn.Conv2d(in_channels = 1, \n",
        "                                              out_channels = n_filters, \n",
        "                                              kernel_size = (fs, embedding_dim)) \n",
        "                                    for fs in filter_sizes\n",
        "                                    ])\n",
        "        \n",
        "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):           \n",
        "        #text = [batch size, sent len]\n",
        "\n",
        "        embedded = self.embedding(text)     \n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "        \n",
        "        embedded = embedded.unsqueeze(1)  \n",
        "        #embedded = [batch size, 1, sent len, emb dim]\n",
        "        \n",
        "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]    \n",
        "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
        "                \n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]     \n",
        "        #pooled_n = [batch size, n_filters]\n",
        "        \n",
        "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
        "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
        "            \n",
        "        return self.fc(cat)\n",
        "\n",
        "\n",
        "def multi_label_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    confusion_vector = rounded_preds / y\n",
        "\n",
        "    true_positives = torch.sum(confusion_vector==1)\n",
        "    false_positives = torch.sum(torch.isinf(confusion_vector)) \n",
        "    false_negatives = torch.sum(confusion_vector==0)\n",
        "    true_negatives = torch.sum(torch.isnan(confusion_vector)) \n",
        "\n",
        "    accuracy = (true_positives + true_negatives) / (true_positives + false_positives + false_negatives + true_negatives)\n",
        "    precision = true_positives / (true_positives + false_positives)\n",
        "    recall = true_positives / (true_positives + false_negatives)\n",
        "    f_score = (2 * precision * recall) / (precision + recall)\n",
        "    \n",
        "    return accuracy, precision, recall, f_score\n",
        "\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    epoch_precision = 0\n",
        "    epoch_recall = 0\n",
        "    epoch_f_score = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(batch[0]).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch[1])\n",
        "        \n",
        "        acc, precision, recall, f_score = multi_label_accuracy(predictions, batch[1])\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        epoch_precision += precision.item()\n",
        "        epoch_recall += recall.item()\n",
        "        epoch_f_score += f_score.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator), \\\n",
        "        epoch_precision / len(iterator), epoch_recall / len(iterator), \\\n",
        "        epoch_f_score / len(iterator)\n",
        "        \n",
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    epoch_precision = 0\n",
        "    epoch_recall = 0\n",
        "    epoch_f_score = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch[0]).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch[1])\n",
        "            \n",
        "            acc, precision, recall, f_score = multi_label_accuracy(predictions, batch[1])\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "            epoch_precision += precision.item()\n",
        "            epoch_recall += recall.item()\n",
        "            epoch_f_score += f_score.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator), \\\n",
        "        epoch_precision / len(iterator), epoch_recall / len(iterator), \\\n",
        "        epoch_f_score / len(iterator)\n",
        "        \n",
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e0JyfjYL71w"
      },
      "source": [
        "\n",
        "class NYTDataSet(Dataset):\n",
        "    def __init__(self, vectorized_data):\n",
        "        self.data = vectorized_data\n",
        "  \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mY0-pAwpEn4B"
      },
      "source": [
        "pretrain = Pretrain(VEC_PATH, MAX_VOCAB)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3nsAvXhZjkZ",
        "outputId": "6509904e-448b-46ef-f44d-d02dd6bea43f"
      },
      "source": [
        "\n",
        "# Check if we are running on a CPU or GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfVSEjTa6T0T"
      },
      "source": [
        "def load(file_path):\n",
        "    vectorized_data = torch.load(file_path)\n",
        "    dataset = NYTDataSet(vectorized_data=vectorized_data)\n",
        "\n",
        "    # Creating data indices for training and validation splits:\n",
        "    dataset_size = len(dataset)\n",
        "    indices = list(range(dataset_size))\n",
        "    split = int(np.floor(validation_split * dataset_size))\n",
        "    if shuffle_dataset:\n",
        "        np.random.seed(random_seed)\n",
        "        np.random.shuffle(indices)\n",
        "    train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "    # Creating PT data samplers and loaders:\n",
        "    train_sampler = SubsetRandomSampler(train_indices)\n",
        "    valid_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, collate_fn=pad_sequences)\n",
        "    validation_loader = DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, collate_fn=pad_sequences)\n",
        "    return dataset_size, train_loader, validation_loader"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAMomkn98SE5"
      },
      "source": [
        "INPUT_DIM = len(pretrain.vocab)\n",
        "EMBEDDING_DIM = pretrain.emb.shape[1]\n",
        "N_FILTERS = 100\n",
        "FILTER_SIZES = [3,4,5,6]\n",
        "OUTPUT_DIM = 538\n",
        "DROPOUT = 0.6\n",
        "\n",
        "model_file_name = 'nyt_cnn_classifier_all_train_vect.pt'\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "EJp7AOCydb6C",
        "outputId": "3a3375a5-ceba-47ca-a0da-01f676ebd678"
      },
      "source": [
        "\n",
        "\n",
        "model = CNN(pretrain, INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_ID)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "run = wandb.init(\n",
        "    entity='ut-mit-news-classify',\n",
        "    project=\"NYT Multilabeling\",\n",
        ")\n",
        "# Magic\n",
        "wandb.watch(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading pretrained vectors from vector_cache/wiki-news-300d-1M.vec...\n",
            "Done Reading\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkristjan\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.27<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">peach-darkness-15</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/ut-mit-news-classify/NYT%20Multilabeling\" target=\"_blank\">https://wandb.ai/ut-mit-news-classify/NYT%20Multilabeling</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/ut-mit-news-classify/NYT%20Multilabeling/runs/37n18fhp\" target=\"_blank\">https://wandb.ai/ut-mit-news-classify/NYT%20Multilabeling/runs/37n18fhp</a><br/>\n",
              "                Run data is saved locally in <code>/content/drive/My Drive/Colab Notebooks/NLP/project/wandb/run-20210425_011853-37n18fhp</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<wandb.wandb_torch.TorchGraph at 0x7f028a5e50d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1w-7ntg32IR",
        "outputId": "4b3bfb5d-7a8b-407e-f986-9807748d14a9"
      },
      "source": [
        "%%time\n",
        "\n",
        "import gc\n",
        "import os\n",
        "\n",
        "patience = 4\n",
        "wandb.config.early_stopping_patience = patience\n",
        "\n",
        "n_training_samples=1298504\n",
        "wandb.config.training_samples=n_training_samples\n",
        "\n",
        "directory = 'all_train_vect'\n",
        "\n",
        "for filename in sorted(os.listdir(directory), key=lambda f: int(f.split(\"_\")[0])):\n",
        "    if filename.endswith(\".pt\"): \n",
        "        dataset_size, train_loader, validation_loader = load(os.path.join(directory, filename))\n",
        "        print('file ', filename)\n",
        "\n",
        "        run_training(model, train_loader, validation_loader, model_file_name, patience)\n",
        "    gc.collect()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "file  0_64926.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New validation loss 0.02631804791019588 is better than the best validation loss inf so far.\n",
            "Epoch: 01 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.038 | Train Acc: 99.29% | Train Precision: nan% | Train Recall: 3.63% | Train F1-score: nan%\n",
            "\t Val. Loss: 0.026 |  Val. Acc: 99.46% | Val. Precision: 88.64% | Val. Recall: 6.42% | Val. F1-score: 11.89%\n",
            "New validation loss 0.02339091734563718 is better than the best validation loss 0.02631804791019588 so far.\n",
            "Epoch: 02 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.026 | Train Acc: 99.46% | Train Precision: 71.24% | Train Recall: 10.74% | Train F1-score: 18.45%\n",
            "\t Val. Loss: 0.023 |  Val. Acc: 99.48% | Val. Precision: 85.62% | Val. Recall: 11.73% | Val. F1-score: 20.52%\n",
            "New validation loss 0.0211553798530434 is better than the best validation loss 0.02339091734563718 so far.\n",
            "Epoch: 03 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.024 | Train Acc: 99.48% | Train Precision: 71.35% | Train Recall: 15.46% | Train F1-score: nan%\n",
            "\t Val. Loss: 0.021 |  Val. Acc: 99.50% | Val. Precision: 87.60% | Val. Recall: 15.19% | Val. F1-score: 25.74%\n",
            "New validation loss 0.019843800591885067 is better than the best validation loss 0.0211553798530434 so far.\n",
            "Epoch: 04 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.022 | Train Acc: 99.49% | Train Precision: 71.38% | Train Recall: 19.11% | Train F1-score: 29.91%\n",
            "\t Val. Loss: 0.020 |  Val. Acc: 99.52% | Val. Precision: 87.52% | Val. Recall: 18.06% | Val. F1-score: 29.81%\n",
            "New validation loss 0.018938066911135542 is better than the best validation loss 0.019843800591885067 so far.\n",
            "Epoch: 05 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.021 | Train Acc: 99.50% | Train Precision: 71.84% | Train Recall: 21.89% | Train F1-score: 33.33%\n",
            "\t Val. Loss: 0.019 |  Val. Acc: 99.53% | Val. Precision: 87.20% | Val. Recall: 19.84% | Val. F1-score: 32.15%\n",
            "New validation loss 0.01824581152225127 is better than the best validation loss 0.018938066911135542 so far.\n",
            "Epoch: 06 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.020 | Train Acc: 99.51% | Train Precision: 72.02% | Train Recall: 23.90% | Train F1-score: 35.65%\n",
            "\t Val. Loss: 0.018 |  Val. Acc: 99.53% | Val. Precision: 85.77% | Val. Recall: 21.95% | Val. F1-score: 34.78%\n",
            "New validation loss 0.017566807583340855 is better than the best validation loss 0.01824581152225127 so far.\n",
            "Epoch: 07 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.020 | Train Acc: 99.52% | Train Precision: 72.16% | Train Recall: 25.73% | Train F1-score: 37.71%\n",
            "\t Val. Loss: 0.018 |  Val. Acc: 99.54% | Val. Precision: 86.06% | Val. Recall: 24.15% | Val. F1-score: 37.52%\n",
            "New validation loss 0.017180231222730193 is better than the best validation loss 0.017566807583340855 so far.\n",
            "Epoch: 08 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.019 | Train Acc: 99.52% | Train Precision: 72.61% | Train Recall: 27.21% | Train F1-score: 39.33%\n",
            "\t Val. Loss: 0.017 |  Val. Acc: 99.55% | Val. Precision: 87.17% | Val. Recall: 24.83% | Val. F1-score: 38.49%\n",
            "New validation loss 0.016964684997792127 is better than the best validation loss 0.017180231222730193 so far.\n",
            "Epoch: 09 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.019 | Train Acc: 99.53% | Train Precision: 73.00% | Train Recall: 28.37% | Train F1-score: 40.62%\n",
            "\t Val. Loss: 0.017 |  Val. Acc: 99.55% | Val. Precision: 84.32% | Val. Recall: 26.90% | Val. F1-score: 40.61%\n",
            "New validation loss 0.016744733959069995 is better than the best validation loss 0.016964684997792127 so far.\n",
            "Epoch: 10 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.018 | Train Acc: 99.53% | Train Precision: 73.16% | Train Recall: 29.57% | Train F1-score: 41.87%\n",
            "\t Val. Loss: 0.017 |  Val. Acc: 99.56% | Val. Precision: 86.61% | Val. Recall: 26.59% | Val. F1-score: 40.51%\n",
            "Epoch: 11 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.018 | Train Acc: 99.54% | Train Precision: 73.73% | Train Recall: 30.61% | Train F1-score: 43.04%\n",
            "\t Val. Loss: 0.017 |  Val. Acc: 99.56% | Val. Precision: 87.36% | Val. Recall: 26.41% | Val. F1-score: 40.38%\n",
            "New validation loss 0.01638104799890616 is better than the best validation loss 0.016744733959069995 so far.\n",
            "Epoch: 12 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.018 | Train Acc: 99.54% | Train Precision: 73.89% | Train Recall: 31.69% | Train F1-score: 44.15%\n",
            "\t Val. Loss: 0.016 |  Val. Acc: 99.56% | Val. Precision: 86.16% | Val. Recall: 28.34% | Val. F1-score: 42.48%\n",
            "Epoch: 13 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.55% | Train Precision: 74.08% | Train Recall: 32.38% | Train F1-score: 44.84%\n",
            "\t Val. Loss: 0.017 |  Val. Acc: 99.56% | Val. Precision: 87.14% | Val. Recall: 27.11% | Val. F1-score: 41.17%\n",
            "Epoch: 14 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.55% | Train Precision: 74.32% | Train Recall: 33.15% | Train F1-score: 45.66%\n",
            "\t Val. Loss: 0.016 |  Val. Acc: 99.57% | Val. Precision: 85.87% | Val. Recall: 28.70% | Val. F1-score: 42.86%\n",
            "New validation loss 0.01625717731162173 is better than the best validation loss 0.01638104799890616 so far.\n",
            "Epoch: 15 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.55% | Train Precision: 74.48% | Train Recall: 33.83% | Train F1-score: 46.29%\n",
            "\t Val. Loss: 0.016 |  Val. Acc: 99.57% | Val. Precision: 85.15% | Val. Recall: 30.13% | Val. F1-score: 44.31%\n",
            "New validation loss 0.016217872827145898 is better than the best validation loss 0.01625717731162173 so far.\n",
            "Epoch: 16 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.56% | Train Precision: 74.88% | Train Recall: 34.63% | Train F1-score: 47.11%\n",
            "\t Val. Loss: 0.016 |  Val. Acc: 99.57% | Val. Precision: 87.01% | Val. Recall: 28.98% | Val. F1-score: 43.29%\n",
            "New validation loss 0.016030932910984657 is better than the best validation loss 0.016217872827145898 so far.\n",
            "Epoch: 17 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.56% | Train Precision: 75.42% | Train Recall: 35.31% | Train F1-score: 47.88%\n",
            "\t Val. Loss: 0.016 |  Val. Acc: 99.57% | Val. Precision: 86.16% | Val. Recall: 30.46% | Val. F1-score: 44.82%\n",
            "Epoch: 18 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.56% | Train Precision: 75.07% | Train Recall: 35.74% | Train F1-score: 48.21%\n",
            "\t Val. Loss: 0.016 |  Val. Acc: 99.57% | Val. Precision: 87.68% | Val. Recall: 29.22% | Val. F1-score: 43.64%\n",
            "New validation loss 0.016026819866822393 is better than the best validation loss 0.016030932910984657 so far.\n",
            "Epoch: 19 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.57% | Train Precision: 75.34% | Train Recall: 36.32% | Train F1-score: 48.81%\n",
            "\t Val. Loss: 0.016 |  Val. Acc: 99.58% | Val. Precision: 85.55% | Val. Recall: 31.13% | Val. F1-score: 45.46%\n",
            "New validation loss 0.015934250723631655 is better than the best validation loss 0.016026819866822393 so far.\n",
            "Epoch: 20 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.57% | Train Precision: 75.79% | Train Recall: 37.06% | Train F1-score: 49.54%\n",
            "\t Val. Loss: 0.016 |  Val. Acc: 99.58% | Val. Precision: 85.52% | Val. Recall: 31.27% | Val. F1-score: 45.64%\n",
            "Epoch: 21 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.57% | Train Precision: 75.86% | Train Recall: 37.41% | Train F1-score: 49.88%\n",
            "\t Val. Loss: 0.016 |  Val. Acc: 99.58% | Val. Precision: 87.19% | Val. Recall: 30.40% | Val. F1-score: 44.91%\n",
            "Epoch: 22 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 76.22% | Train Recall: 37.98% | Train F1-score: 50.47%\n",
            "\t Val. Loss: 0.016 |  Val. Acc: 99.58% | Val. Precision: 85.83% | Val. Recall: 31.17% | Val. F1-score: 45.53%\n",
            "Epoch: 23 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.58% | Train Precision: 76.54% | Train Recall: 38.50% | Train F1-score: 51.00%\n",
            "\t Val. Loss: 0.016 |  Val. Acc: 99.58% | Val. Precision: 85.92% | Val. Recall: 31.47% | Val. F1-score: 45.89%\n",
            "New validation loss 0.01578681291859658 is better than the best validation loss 0.015934250723631655 so far.\n",
            "Epoch: 24 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.58% | Train Precision: 76.70% | Train Recall: 38.93% | Train F1-score: 51.46%\n",
            "\t Val. Loss: 0.016 |  Val. Acc: 99.58% | Val. Precision: 85.65% | Val. Recall: 32.31% | Val. F1-score: 46.74%\n",
            "Epoch: 25 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.58% | Train Precision: 76.75% | Train Recall: 39.38% | Train F1-score: 51.86%\n",
            "\t Val. Loss: 0.016 |  Val. Acc: 99.58% | Val. Precision: 87.09% | Val. Recall: 31.19% | Val. F1-score: 45.76%\n",
            "Epoch: 26 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 76.85% | Train Recall: 39.75% | Train F1-score: 52.21%\n",
            "\t Val. Loss: 0.016 |  Val. Acc: 99.58% | Val. Precision: 85.40% | Val. Recall: 32.04% | Val. F1-score: 46.43%\n",
            "Epoch: 27 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 76.95% | Train Recall: 40.31% | Train F1-score: 52.72%\n",
            "\t Val. Loss: 0.016 |  Val. Acc: 99.58% | Val. Precision: 87.21% | Val. Recall: 31.47% | Val. F1-score: 46.09%\n",
            "Epoch: 28 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 77.36% | Train Recall: 40.74% | Train F1-score: 53.18%\n",
            "\t Val. Loss: 0.016 |  Val. Acc: 99.58% | Val. Precision: 86.10% | Val. Recall: 31.95% | Val. F1-score: 46.43%\n",
            "Early stopping, on epoch: 28.\n",
            "file  1_64926.pt\n",
            "New validation loss 0.01610222237764812 is better than the best validation loss inf so far.\n",
            "Epoch: 01 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.019 | Train Acc: 99.54% | Train Precision: 72.13% | Train Recall: 31.68% | Train F1-score: 43.78%\n",
            "\t Val. Loss: 0.016 |  Val. Acc: 99.57% | Val. Precision: 86.14% | Val. Recall: 30.86% | Val. F1-score: 45.27%\n",
            "New validation loss 0.01592006954501887 is better than the best validation loss 0.01610222237764812 so far.\n",
            "Epoch: 02 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.018 | Train Acc: 99.55% | Train Precision: 73.32% | Train Recall: 33.15% | Train F1-score: 45.44%\n",
            "\t Val. Loss: 0.016 |  Val. Acc: 99.57% | Val. Precision: 88.08% | Val. Recall: 30.25% | Val. F1-score: 44.85%\n",
            "New validation loss 0.015557274146036047 is better than the best validation loss 0.01592006954501887 so far.\n",
            "Epoch: 03 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.56% | Train Precision: 74.04% | Train Recall: 34.23% | Train F1-score: 46.58%\n",
            "\t Val. Loss: 0.016 |  Val. Acc: 99.58% | Val. Precision: 86.42% | Val. Recall: 32.49% | Val. F1-score: 47.06%\n",
            "New validation loss 0.015538368722210165 is better than the best validation loss 0.015557274146036047 so far.\n",
            "Epoch: 04 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.56% | Train Precision: 74.45% | Train Recall: 35.17% | Train F1-score: 47.54%\n",
            "\t Val. Loss: 0.016 |  Val. Acc: 99.58% | Val. Precision: 86.68% | Val. Recall: 32.75% | Val. F1-score: 47.33%\n",
            "New validation loss 0.01545994336121395 is better than the best validation loss 0.015538368722210165 so far.\n",
            "Epoch: 05 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.56% | Train Precision: 74.78% | Train Recall: 35.88% | Train F1-score: 48.27%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.58% | Val. Precision: 86.44% | Val. Recall: 32.72% | Val. F1-score: 47.29%\n",
            "Epoch: 06 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.57% | Train Precision: 75.36% | Train Recall: 36.60% | Train F1-score: 49.05%\n",
            "\t Val. Loss: 0.016 |  Val. Acc: 99.58% | Val. Precision: 86.62% | Val. Recall: 33.17% | Val. F1-score: 47.77%\n",
            "Epoch: 07 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.57% | Train Precision: 75.50% | Train Recall: 37.37% | Train F1-score: 49.80%\n",
            "\t Val. Loss: 0.016 |  Val. Acc: 99.58% | Val. Precision: 88.39% | Val. Recall: 31.65% | Val. F1-score: 46.43%\n",
            "New validation loss 0.015418318732351553 is better than the best validation loss 0.01545994336121395 so far.\n",
            "Epoch: 08 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 75.89% | Train Recall: 37.93% | Train F1-score: 50.36%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 86.49% | Val. Recall: 33.85% | Val. F1-score: 48.46%\n",
            "Epoch: 09 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 76.45% | Train Recall: 38.55% | Train F1-score: 51.07%\n",
            "\t Val. Loss: 0.016 |  Val. Acc: 99.59% | Val. Precision: 86.73% | Val. Recall: 33.35% | Val. F1-score: 47.99%\n",
            "Epoch: 10 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.58% | Train Precision: 76.61% | Train Recall: 39.16% | Train F1-score: 51.62%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 86.22% | Val. Recall: 34.22% | Val. F1-score: 48.79%\n",
            "New validation loss 0.015365134371963681 is better than the best validation loss 0.015418318732351553 so far.\n",
            "Epoch: 11 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 76.88% | Train Recall: 39.64% | Train F1-score: 52.12%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 85.33% | Val. Recall: 35.16% | Val. F1-score: 49.60%\n",
            "Epoch: 12 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 77.01% | Train Recall: 40.12% | Train F1-score: 52.55%\n",
            "\t Val. Loss: 0.016 |  Val. Acc: 99.59% | Val. Precision: 87.08% | Val. Recall: 33.51% | Val. F1-score: 48.19%\n",
            "Epoch: 13 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 77.21% | Train Recall: 40.33% | Train F1-score: 52.78%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 85.90% | Val. Recall: 34.65% | Val. F1-score: 49.21%\n",
            "Epoch: 14 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 77.27% | Train Recall: 41.00% | Train F1-score: 53.37%\n",
            "\t Val. Loss: 0.016 |  Val. Acc: 99.59% | Val. Precision: 86.65% | Val. Recall: 33.79% | Val. F1-score: 48.42%\n",
            "Epoch: 15 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.60% | Train Precision: 77.65% | Train Recall: 41.31% | Train F1-score: 53.73%\n",
            "\t Val. Loss: 0.016 |  Val. Acc: 99.59% | Val. Precision: 86.84% | Val. Recall: 33.66% | Val. F1-score: 48.32%\n",
            "Early stopping, on epoch: 15.\n",
            "file  2_64926.pt\n",
            "New validation loss 0.015317264709194176 is better than the best validation loss inf so far.\n",
            "Epoch: 01 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.018 | Train Acc: 99.55% | Train Precision: 72.43% | Train Recall: 32.98% | Train F1-score: 45.10%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 86.92% | Val. Recall: 32.04% | Val. F1-score: 46.64%\n",
            "New validation loss 0.015312465973442695 is better than the best validation loss 0.015317264709194176 so far.\n",
            "Epoch: 02 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.018 | Train Acc: 99.55% | Train Precision: 73.70% | Train Recall: 34.28% | Train F1-score: 46.57%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 87.28% | Val. Recall: 31.71% | Val. F1-score: 46.34%\n",
            "New validation loss 0.015262670216501736 is better than the best validation loss 0.015312465973442695 so far.\n",
            "Epoch: 03 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.56% | Train Precision: 74.33% | Train Recall: 35.46% | Train F1-score: 47.81%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 86.44% | Val. Recall: 32.73% | Val. F1-score: 47.29%\n",
            "Epoch: 04 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.57% | Train Precision: 74.74% | Train Recall: 36.46% | Train F1-score: 48.81%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 86.70% | Val. Recall: 32.54% | Val. F1-score: 47.08%\n",
            "New validation loss 0.015244239132057448 is better than the best validation loss 0.015262670216501736 so far.\n",
            "Epoch: 05 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.57% | Train Precision: 75.86% | Train Recall: 37.34% | Train F1-score: 49.84%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 86.01% | Val. Recall: 33.39% | Val. F1-score: 47.89%\n",
            "Epoch: 06 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 75.74% | Train Recall: 37.74% | Train F1-score: 50.17%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 87.10% | Val. Recall: 32.34% | Val. F1-score: 46.99%\n",
            "New validation loss 0.01518198246533265 is better than the best validation loss 0.015244239132057448 so far.\n",
            "Epoch: 07 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 76.01% | Train Recall: 38.23% | Train F1-score: 50.67%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 86.25% | Val. Recall: 33.29% | Val. F1-score: 47.85%\n",
            "New validation loss 0.015110843045423265 is better than the best validation loss 0.01518198246533265 so far.\n",
            "Epoch: 08 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.58% | Train Precision: 76.41% | Train Recall: 39.04% | Train F1-score: 51.45%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 85.91% | Val. Recall: 33.85% | Val. F1-score: 48.39%\n",
            "Epoch: 09 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 76.75% | Train Recall: 39.32% | Train F1-score: 51.79%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 86.96% | Val. Recall: 32.99% | Val. F1-score: 47.67%\n",
            "Epoch: 10 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 76.98% | Train Recall: 39.95% | Train F1-score: 52.42%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 86.69% | Val. Recall: 33.53% | Val. F1-score: 48.14%\n",
            "Epoch: 11 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 77.58% | Train Recall: 40.74% | Train F1-score: 53.23%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 86.39% | Val. Recall: 33.19% | Val. F1-score: 47.74%\n",
            "Epoch: 12 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.60% | Train Precision: 77.62% | Train Recall: 41.09% | Train F1-score: 53.54%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 85.76% | Val. Recall: 34.71% | Val. F1-score: 49.25%\n",
            "Early stopping, on epoch: 12.\n",
            "file  3_64926.pt\n",
            "New validation loss 0.015249745556932004 is better than the best validation loss inf so far.\n",
            "Epoch: 01 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.018 | Train Acc: 99.55% | Train Precision: 72.87% | Train Recall: 33.60% | Train F1-score: 45.78%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.58% | Val. Precision: 88.37% | Val. Recall: 31.80% | Val. F1-score: 46.58%\n",
            "New validation loss 0.015201064889303973 is better than the best validation loss 0.015249745556932004 so far.\n",
            "Epoch: 02 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.56% | Train Precision: 73.89% | Train Recall: 35.04% | Train F1-score: 47.32%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 88.23% | Val. Recall: 32.28% | Val. F1-score: 47.07%\n",
            "New validation loss 0.015102738706914127 is better than the best validation loss 0.015201064889303973 so far.\n",
            "Epoch: 03 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.56% | Train Precision: 74.73% | Train Recall: 35.99% | Train F1-score: 48.36%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 87.61% | Val. Recall: 32.84% | Val. F1-score: 47.57%\n",
            "Epoch: 04 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.57% | Train Precision: 75.12% | Train Recall: 36.91% | Train F1-score: 49.32%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 87.77% | Val. Recall: 32.75% | Val. F1-score: 47.51%\n",
            "New validation loss 0.014948846845597517 is better than the best validation loss 0.015102738706914127 so far.\n",
            "Epoch: 05 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.57% | Train Precision: 75.71% | Train Recall: 37.69% | Train F1-score: 50.13%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 86.34% | Val. Recall: 34.52% | Val. F1-score: 49.11%\n",
            "Epoch: 06 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 76.19% | Train Recall: 38.39% | Train F1-score: 50.85%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 87.20% | Val. Recall: 33.71% | Val. F1-score: 48.41%\n",
            "Epoch: 07 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 76.57% | Train Recall: 38.77% | Train F1-score: 51.27%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 86.39% | Val. Recall: 34.55% | Val. F1-score: 49.19%\n",
            "New validation loss 0.014933806929554119 is better than the best validation loss 0.014948846845597517 so far.\n",
            "Epoch: 08 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 76.76% | Train Recall: 39.36% | Train F1-score: 51.86%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 85.81% | Val. Recall: 35.29% | Val. F1-score: 49.83%\n",
            "Epoch: 09 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 77.18% | Train Recall: 40.15% | Train F1-score: 52.63%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 87.71% | Val. Recall: 32.93% | Val. F1-score: 47.72%\n",
            "Epoch: 10 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 77.18% | Train Recall: 40.44% | Train F1-score: 52.86%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 87.59% | Val. Recall: 33.68% | Val. F1-score: 48.46%\n",
            "Epoch: 11 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 77.59% | Train Recall: 40.86% | Train F1-score: 53.34%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 86.01% | Val. Recall: 35.82% | Val. F1-score: 50.37%\n",
            "Epoch: 12 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.60% | Train Precision: 77.72% | Train Recall: 41.32% | Train F1-score: 53.76%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 86.98% | Val. Recall: 34.57% | Val. F1-score: 49.27%\n",
            "Early stopping, on epoch: 12.\n",
            "file  4_64925.pt\n",
            "New validation loss 0.015121030343360589 is better than the best validation loss inf so far.\n",
            "Epoch: 01 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.018 | Train Acc: 99.55% | Train Precision: 72.85% | Train Recall: 33.54% | Train F1-score: 45.72%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 86.74% | Val. Recall: 33.68% | Val. F1-score: 48.33%\n",
            "New validation loss 0.014996569869337511 is better than the best validation loss 0.015121030343360589 so far.\n",
            "Epoch: 02 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.56% | Train Precision: 74.05% | Train Recall: 35.31% | Train F1-score: 47.61%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 86.93% | Val. Recall: 34.26% | Val. F1-score: 48.96%\n",
            "New validation loss 0.01495419289061769 is better than the best validation loss 0.014996569869337511 so far.\n",
            "Epoch: 03 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.57% | Train Precision: 74.83% | Train Recall: 36.20% | Train F1-score: 48.59%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 87.02% | Val. Recall: 34.26% | Val. F1-score: 48.97%\n",
            "New validation loss 0.014735517577558267 is better than the best validation loss 0.01495419289061769 so far.\n",
            "Epoch: 04 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.57% | Train Precision: 75.45% | Train Recall: 36.96% | Train F1-score: 49.40%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 85.93% | Val. Recall: 36.25% | Val. F1-score: 50.79%\n",
            "Epoch: 05 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 75.83% | Train Recall: 37.89% | Train F1-score: 50.31%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 86.92% | Val. Recall: 34.99% | Val. F1-score: 49.69%\n",
            "Epoch: 06 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 76.36% | Train Recall: 38.67% | Train F1-score: 51.14%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 87.47% | Val. Recall: 34.46% | Val. F1-score: 49.26%\n",
            "Epoch: 07 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.58% | Train Precision: 76.63% | Train Recall: 39.14% | Train F1-score: 51.62%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 86.79% | Val. Recall: 34.82% | Val. F1-score: 49.50%\n",
            "Epoch: 08 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 76.81% | Train Recall: 39.60% | Train F1-score: 52.07%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 86.80% | Val. Recall: 34.94% | Val. F1-score: 49.66%\n",
            "Early stopping, on epoch: 8.\n",
            "file  5_64925.pt\n",
            "New validation loss 0.014984139928319415 is better than the best validation loss inf so far.\n",
            "Epoch: 01 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.018 | Train Acc: 99.55% | Train Precision: 72.78% | Train Recall: 34.17% | Train F1-score: 46.30%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 87.74% | Val. Recall: 33.47% | Val. F1-score: 48.26%\n",
            "New validation loss 0.014955097009412577 is better than the best validation loss 0.014984139928319415 so far.\n",
            "Epoch: 02 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.56% | Train Precision: 73.80% | Train Recall: 35.40% | Train F1-score: 47.62%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 87.53% | Val. Recall: 33.85% | Val. F1-score: 48.66%\n",
            "New validation loss 0.014828311972564361 is better than the best validation loss 0.014955097009412577 so far.\n",
            "Epoch: 03 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.57% | Train Precision: 74.87% | Train Recall: 36.54% | Train F1-score: 48.88%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 86.99% | Val. Recall: 34.47% | Val. F1-score: 49.20%\n",
            "New validation loss 0.014726912260788386 is better than the best validation loss 0.014828311972564361 so far.\n",
            "Epoch: 04 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.57% | Train Precision: 75.50% | Train Recall: 37.39% | Train F1-score: 49.81%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 86.26% | Val. Recall: 35.57% | Val. F1-score: 50.19%\n",
            "Epoch: 05 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 75.76% | Train Recall: 38.16% | Train F1-score: 50.55%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.16% | Val. Recall: 34.42% | Val. F1-score: 49.14%\n",
            "Epoch: 06 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 76.50% | Train Recall: 38.76% | Train F1-score: 51.24%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 85.15% | Val. Recall: 36.65% | Val. F1-score: 51.03%\n",
            "Epoch: 07 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.58% | Train Precision: 76.44% | Train Recall: 39.35% | Train F1-score: 51.75%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 86.55% | Val. Recall: 35.46% | Val. F1-score: 50.13%\n",
            "Epoch: 08 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 76.68% | Train Recall: 39.72% | Train F1-score: 52.16%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.10% | Val. Recall: 34.84% | Val. F1-score: 49.55%\n",
            "Early stopping, on epoch: 8.\n",
            "file  6_64925.pt\n",
            "New validation loss 0.014865706549560438 is better than the best validation loss inf so far.\n",
            "Epoch: 01 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.018 | Train Acc: 99.55% | Train Precision: 73.15% | Train Recall: 34.29% | Train F1-score: 46.45%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 87.88% | Val. Recall: 32.97% | Val. F1-score: 47.76%\n",
            "New validation loss 0.014760818191971935 is better than the best validation loss 0.014865706549560438 so far.\n",
            "Epoch: 02 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.56% | Train Precision: 74.47% | Train Recall: 35.45% | Train F1-score: 47.83%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 86.99% | Val. Recall: 34.27% | Val. F1-score: 48.96%\n",
            "New validation loss 0.014644292842779981 is better than the best validation loss 0.014760818191971935 so far.\n",
            "Epoch: 03 | Epoch Time: 1m 23s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.57% | Train Precision: 75.36% | Train Recall: 36.81% | Train F1-score: 49.25%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 86.59% | Val. Recall: 34.91% | Val. F1-score: 49.58%\n",
            "Epoch: 04 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.57% | Train Precision: 75.38% | Train Recall: 37.65% | Train F1-score: 50.02%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 86.77% | Val. Recall: 34.70% | Val. F1-score: 49.38%\n",
            "Epoch: 05 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.57% | Train Precision: 75.76% | Train Recall: 38.24% | Train F1-score: 50.64%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 86.35% | Val. Recall: 35.30% | Val. F1-score: 49.89%\n",
            "Epoch: 06 | Epoch Time: 1m 23s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 76.45% | Train Recall: 39.03% | Train F1-score: 51.48%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 86.83% | Val. Recall: 34.51% | Val. F1-score: 49.21%\n",
            "Epoch: 07 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.58% | Train Precision: 76.65% | Train Recall: 39.30% | Train F1-score: 51.76%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 87.78% | Val. Recall: 33.49% | Val. F1-score: 48.29%\n",
            "Early stopping, on epoch: 7.\n",
            "file  7_64925.pt\n",
            "New validation loss 0.015006753493894319 is better than the best validation loss inf so far.\n",
            "Epoch: 01 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.018 | Train Acc: 99.55% | Train Precision: 73.49% | Train Recall: 34.58% | Train F1-score: 46.81%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 87.22% | Val. Recall: 33.17% | Val. F1-score: 47.88%\n",
            "New validation loss 0.014794227276302752 is better than the best validation loss 0.015006753493894319 so far.\n",
            "Epoch: 02 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.56% | Train Precision: 74.41% | Train Recall: 35.89% | Train F1-score: 48.23%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 86.08% | Val. Recall: 34.87% | Val. F1-score: 49.44%\n",
            "New validation loss 0.014613954649596918 is better than the best validation loss 0.014794227276302752 so far.\n",
            "Epoch: 03 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.57% | Train Precision: 75.18% | Train Recall: 36.83% | Train F1-score: 49.23%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 86.24% | Val. Recall: 35.24% | Val. F1-score: 49.83%\n",
            "Epoch: 04 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.57% | Train Precision: 75.81% | Train Recall: 37.73% | Train F1-score: 50.18%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 86.91% | Val. Recall: 34.95% | Val. F1-score: 49.64%\n",
            "Epoch: 05 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.57% | Train Precision: 76.00% | Train Recall: 38.41% | Train F1-score: 50.82%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 86.29% | Val. Recall: 35.40% | Val. F1-score: 49.99%\n",
            "Epoch: 06 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 76.57% | Train Recall: 39.00% | Train F1-score: 51.48%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 86.38% | Val. Recall: 35.21% | Val. F1-score: 49.84%\n",
            "Epoch: 07 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 77.18% | Train Recall: 39.89% | Train F1-score: 52.42%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 85.28% | Val. Recall: 36.34% | Val. F1-score: 50.80%\n",
            "Early stopping, on epoch: 7.\n",
            "file  8_64925.pt\n",
            "New validation loss 0.014707106351852416 is better than the best validation loss inf so far.\n",
            "Epoch: 01 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.56% | Train Precision: 73.87% | Train Recall: 34.87% | Train F1-score: 47.18%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 87.04% | Val. Recall: 34.41% | Val. F1-score: 49.13%\n",
            "New validation loss 0.014706993032796462 is better than the best validation loss 0.014707106351852416 so far.\n",
            "Epoch: 02 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.57% | Train Precision: 74.83% | Train Recall: 36.22% | Train F1-score: 48.61%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 87.11% | Val. Recall: 34.37% | Val. F1-score: 49.10%\n",
            "Epoch: 03 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.57% | Train Precision: 75.22% | Train Recall: 37.23% | Train F1-score: 49.60%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 87.76% | Val. Recall: 33.77% | Val. F1-score: 48.60%\n",
            "New validation loss 0.01468616141097956 is better than the best validation loss 0.014706993032796462 so far.\n",
            "Epoch: 04 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 76.00% | Train Recall: 38.13% | Train F1-score: 50.58%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 86.92% | Val. Recall: 34.95% | Val. F1-score: 49.69%\n",
            "Epoch: 05 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 76.31% | Train Recall: 38.70% | Train F1-score: 51.15%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 86.69% | Val. Recall: 35.34% | Val. F1-score: 50.00%\n",
            "Epoch: 06 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 77.04% | Train Recall: 39.59% | Train F1-score: 52.11%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.25% | Val. Recall: 35.11% | Val. F1-score: 49.87%\n",
            "Epoch: 07 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 76.86% | Train Recall: 39.88% | Train F1-score: 52.33%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 86.49% | Val. Recall: 35.40% | Val. F1-score: 50.06%\n",
            "Epoch: 08 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 77.39% | Train Recall: 40.64% | Train F1-score: 53.10%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.42% | Val. Recall: 34.78% | Val. F1-score: 49.58%\n",
            "Early stopping, on epoch: 8.\n",
            "file  9_64925.pt\n",
            "New validation loss 0.014750127610368808 is better than the best validation loss inf so far.\n",
            "Epoch: 01 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.56% | Train Precision: 73.83% | Train Recall: 34.90% | Train F1-score: 47.20%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 87.24% | Val. Recall: 33.85% | Val. F1-score: 48.57%\n",
            "New validation loss 0.014694046752802172 is better than the best validation loss 0.014750127610368808 so far.\n",
            "Epoch: 02 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.56% | Train Precision: 74.79% | Train Recall: 36.09% | Train F1-score: 48.47%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 87.95% | Val. Recall: 33.80% | Val. F1-score: 48.62%\n",
            "Epoch: 03 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.57% | Train Precision: 75.22% | Train Recall: 37.06% | Train F1-score: 49.48%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.51% | Val. Recall: 34.45% | Val. F1-score: 49.26%\n",
            "Epoch: 04 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 76.00% | Train Recall: 37.79% | Train F1-score: 50.27%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.49% | Val. Recall: 34.46% | Val. F1-score: 49.27%\n",
            "Epoch: 05 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 76.31% | Train Recall: 38.61% | Train F1-score: 51.10%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.52% | Val. Recall: 34.71% | Val. F1-score: 49.55%\n",
            "Epoch: 06 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 76.83% | Train Recall: 39.35% | Train F1-score: 51.85%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.31% | Val. Recall: 35.14% | Val. F1-score: 49.92%\n",
            "Early stopping, on epoch: 6.\n",
            "file  10_64925.pt\n",
            "New validation loss 0.014532813042035846 is better than the best validation loss inf so far.\n",
            "Epoch: 01 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.56% | Train Precision: 74.02% | Train Recall: 34.94% | Train F1-score: 47.24%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.69% | Val. Recall: 34.74% | Val. F1-score: 49.57%\n",
            "New validation loss 0.014437127256857567 is better than the best validation loss 0.014532813042035846 so far.\n",
            "Epoch: 02 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.57% | Train Precision: 74.97% | Train Recall: 36.25% | Train F1-score: 48.66%\n",
            "\t Val. Loss: 0.014 |  Val. Acc: 99.60% | Val. Precision: 86.95% | Val. Recall: 35.41% | Val. F1-score: 50.15%\n",
            "Epoch: 03 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.57% | Train Precision: 75.47% | Train Recall: 37.35% | Train F1-score: 49.77%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.71% | Val. Recall: 34.56% | Val. F1-score: 49.41%\n",
            "Epoch: 04 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 75.88% | Train Recall: 37.91% | Train F1-score: 50.36%\n",
            "\t Val. Loss: 0.014 |  Val. Acc: 99.60% | Val. Precision: 87.52% | Val. Recall: 35.33% | Val. F1-score: 50.15%\n",
            "New validation loss 0.014435622960206914 is better than the best validation loss 0.014437127256857567 so far.\n",
            "Epoch: 05 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 76.35% | Train Recall: 38.58% | Train F1-score: 51.07%\n",
            "\t Val. Loss: 0.014 |  Val. Acc: 99.60% | Val. Precision: 85.35% | Val. Recall: 36.99% | Val. F1-score: 51.44%\n",
            "Epoch: 06 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 76.80% | Train Recall: 39.37% | Train F1-score: 51.86%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 86.23% | Val. Recall: 36.44% | Val. F1-score: 51.05%\n",
            "Epoch: 07 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 77.03% | Train Recall: 39.91% | Train F1-score: 52.36%\n",
            "\t Val. Loss: 0.014 |  Val. Acc: 99.60% | Val. Precision: 86.86% | Val. Recall: 35.97% | Val. F1-score: 50.68%\n",
            "Epoch: 08 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 77.29% | Train Recall: 40.27% | Train F1-score: 52.76%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 86.79% | Val. Recall: 36.15% | Val. F1-score: 50.87%\n",
            "Epoch: 09 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 77.66% | Train Recall: 40.90% | Train F1-score: 53.39%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.44% | Val. Recall: 35.64% | Val. F1-score: 50.47%\n",
            "Early stopping, on epoch: 9.\n",
            "file  11_64925.pt\n",
            "New validation loss 0.014757110554053158 is better than the best validation loss inf so far.\n",
            "Epoch: 01 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.018 | Train Acc: 99.56% | Train Precision: 73.52% | Train Recall: 34.53% | Train F1-score: 46.77%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 87.69% | Val. Recall: 33.95% | Val. F1-score: 48.79%\n",
            "New validation loss 0.014733908084205917 is better than the best validation loss 0.014757110554053158 so far.\n",
            "Epoch: 02 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.56% | Train Precision: 74.54% | Train Recall: 35.73% | Train F1-score: 48.10%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 86.92% | Val. Recall: 34.84% | Val. F1-score: 49.58%\n",
            "New validation loss 0.014698433372207352 is better than the best validation loss 0.014733908084205917 so far.\n",
            "Epoch: 03 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.57% | Train Precision: 75.38% | Train Recall: 36.89% | Train F1-score: 49.33%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.89% | Val. Recall: 34.55% | Val. F1-score: 49.39%\n",
            "New validation loss 0.014684766662291815 is better than the best validation loss 0.014698433372207352 so far.\n",
            "Epoch: 04 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 75.77% | Train Recall: 37.77% | Train F1-score: 50.19%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.05% | Val. Recall: 35.26% | Val. F1-score: 49.97%\n",
            "Epoch: 05 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 76.44% | Train Recall: 38.73% | Train F1-score: 51.21%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.13% | Val. Recall: 35.41% | Val. F1-score: 50.16%\n",
            "Epoch: 06 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.58% | Train Precision: 76.59% | Train Recall: 39.12% | Train F1-score: 51.58%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 86.78% | Val. Recall: 35.39% | Val. F1-score: 50.08%\n",
            "Epoch: 07 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 77.11% | Train Recall: 39.73% | Train F1-score: 52.22%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.09% | Val. Recall: 35.21% | Val. F1-score: 49.94%\n",
            "Epoch: 08 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 77.46% | Train Recall: 40.20% | Train F1-score: 52.72%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 86.85% | Val. Recall: 35.93% | Val. F1-score: 50.65%\n",
            "Early stopping, on epoch: 8.\n",
            "file  12_64925.pt\n",
            "New validation loss 0.014629126654663047 is better than the best validation loss inf so far.\n",
            "Epoch: 01 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.56% | Train Precision: 74.01% | Train Recall: 34.72% | Train F1-score: 47.06%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 88.74% | Val. Recall: 33.51% | Val. F1-score: 48.47%\n",
            "New validation loss 0.0145882765136537 is better than the best validation loss 0.014629126654663047 so far.\n",
            "Epoch: 02 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.56% | Train Precision: 74.81% | Train Recall: 35.81% | Train F1-score: 48.22%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.92% | Val. Recall: 34.48% | Val. F1-score: 49.34%\n",
            "New validation loss 0.014499277160426632 is better than the best validation loss 0.0145882765136537 so far.\n",
            "Epoch: 03 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.57% | Train Precision: 75.46% | Train Recall: 36.82% | Train F1-score: 49.28%\n",
            "\t Val. Loss: 0.014 |  Val. Acc: 99.60% | Val. Precision: 87.05% | Val. Recall: 35.10% | Val. F1-score: 49.85%\n",
            "Epoch: 04 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 76.00% | Train Recall: 37.68% | Train F1-score: 50.19%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.90% | Val. Recall: 34.60% | Val. F1-score: 49.46%\n",
            "Epoch: 05 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 76.28% | Train Recall: 38.17% | Train F1-score: 50.70%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.16% | Val. Recall: 35.43% | Val. F1-score: 50.19%\n",
            "New validation loss 0.014475124191920288 is better than the best validation loss 0.014499277160426632 so far.\n",
            "Epoch: 06 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.58% | Train Precision: 76.64% | Train Recall: 38.92% | Train F1-score: 51.43%\n",
            "\t Val. Loss: 0.014 |  Val. Acc: 99.60% | Val. Precision: 86.07% | Val. Recall: 36.47% | Val. F1-score: 51.07%\n",
            "Epoch: 07 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 76.97% | Train Recall: 39.62% | Train F1-score: 52.13%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.28% | Val. Recall: 35.43% | Val. F1-score: 50.22%\n",
            "Epoch: 08 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 77.15% | Train Recall: 40.03% | Train F1-score: 52.51%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 86.91% | Val. Recall: 36.17% | Val. F1-score: 50.87%\n",
            "Epoch: 09 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 77.74% | Train Recall: 40.56% | Train F1-score: 53.12%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.22% | Val. Recall: 35.53% | Val. F1-score: 50.32%\n",
            "Epoch: 10 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.60% | Train Precision: 77.81% | Train Recall: 40.83% | Train F1-score: 53.36%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 86.90% | Val. Recall: 35.71% | Val. F1-score: 50.45%\n",
            "Early stopping, on epoch: 10.\n",
            "file  13_64925.pt\n",
            "New validation loss 0.014904960974684505 is better than the best validation loss inf so far.\n",
            "Epoch: 01 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.56% | Train Precision: 74.02% | Train Recall: 35.00% | Train F1-score: 47.31%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 88.02% | Val. Recall: 33.36% | Val. F1-score: 48.20%\n",
            "New validation loss 0.014771615881778178 is better than the best validation loss 0.014904960974684505 so far.\n",
            "Epoch: 02 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.57% | Train Precision: 74.76% | Train Recall: 36.11% | Train F1-score: 48.50%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 87.76% | Val. Recall: 34.19% | Val. F1-score: 49.01%\n",
            "New validation loss 0.014766308390459077 is better than the best validation loss 0.014771615881778178 so far.\n",
            "Epoch: 03 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.57% | Train Precision: 75.48% | Train Recall: 37.14% | Train F1-score: 49.57%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.33% | Val. Recall: 34.88% | Val. F1-score: 49.65%\n",
            "New validation loss 0.0147063835508755 is better than the best validation loss 0.014766308390459077 so far.\n",
            "Epoch: 04 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 76.16% | Train Recall: 38.00% | Train F1-score: 50.50%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.43% | Val. Recall: 35.16% | Val. F1-score: 49.99%\n",
            "New validation loss 0.014678715511423643 is better than the best validation loss 0.0147063835508755 so far.\n",
            "Epoch: 05 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 76.71% | Train Recall: 38.82% | Train F1-score: 51.35%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 86.85% | Val. Recall: 35.79% | Val. F1-score: 50.49%\n",
            "Epoch: 06 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 76.70% | Train Recall: 39.47% | Train F1-score: 51.94%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.96% | Val. Recall: 34.52% | Val. F1-score: 49.38%\n",
            "Epoch: 07 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 77.27% | Train Recall: 40.00% | Train F1-score: 52.53%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.17% | Val. Recall: 35.48% | Val. F1-score: 50.23%\n",
            "Epoch: 08 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 77.59% | Train Recall: 40.35% | Train F1-score: 52.92%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.01% | Val. Recall: 35.99% | Val. F1-score: 50.73%\n",
            "Epoch: 09 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.60% | Train Precision: 77.70% | Train Recall: 40.85% | Train F1-score: 53.35%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.20% | Val. Recall: 35.35% | Val. F1-score: 50.12%\n",
            "Early stopping, on epoch: 9.\n",
            "file  14_64925.pt\n",
            "New validation loss 0.01448021797677044 is better than the best validation loss inf so far.\n",
            "Epoch: 01 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.56% | Train Precision: 73.61% | Train Recall: 34.33% | Train F1-score: 46.60%\n",
            "\t Val. Loss: 0.014 |  Val. Acc: 99.60% | Val. Precision: 87.76% | Val. Recall: 34.74% | Val. F1-score: 49.57%\n",
            "Epoch: 02 | Epoch Time: 1m 23s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.57% | Train Precision: 74.55% | Train Recall: 35.67% | Train F1-score: 48.05%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 88.23% | Val. Recall: 34.37% | Val. F1-score: 49.27%\n",
            "Epoch: 03 | Epoch Time: 1m 23s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.57% | Train Precision: 75.23% | Train Recall: 36.61% | Train F1-score: 49.06%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.97% | Val. Recall: 34.43% | Val. F1-score: 49.29%\n",
            "New validation loss 0.01441713058252315 is better than the best validation loss 0.01448021797677044 so far.\n",
            "Epoch: 04 | Epoch Time: 1m 23s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 75.96% | Train Recall: 37.55% | Train F1-score: 50.05%\n",
            "\t Val. Loss: 0.014 |  Val. Acc: 99.61% | Val. Precision: 86.46% | Val. Recall: 36.02% | Val. F1-score: 50.61%\n",
            "Epoch: 05 | Epoch Time: 1m 23s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 76.10% | Train Recall: 38.23% | Train F1-score: 50.68%\n",
            "\t Val. Loss: 0.014 |  Val. Acc: 99.60% | Val. Precision: 87.55% | Val. Recall: 35.26% | Val. F1-score: 50.05%\n",
            "Epoch: 06 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 76.67% | Train Recall: 38.83% | Train F1-score: 51.36%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.61% | Val. Precision: 87.11% | Val. Recall: 35.65% | Val. F1-score: 50.42%\n",
            "Epoch: 07 | Epoch Time: 1m 23s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 77.11% | Train Recall: 39.56% | Train F1-score: 52.09%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.61% | Val. Precision: 87.65% | Val. Recall: 35.44% | Val. F1-score: 50.27%\n",
            "Epoch: 08 | Epoch Time: 1m 23s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 77.19% | Train Recall: 40.18% | Train F1-score: 52.65%\n",
            "\t Val. Loss: 0.014 |  Val. Acc: 99.61% | Val. Precision: 87.25% | Val. Recall: 35.79% | Val. F1-score: 50.59%\n",
            "Early stopping, on epoch: 8.\n",
            "file  15_64925.pt\n",
            "New validation loss 0.014417269832042397 is better than the best validation loss inf so far.\n",
            "Epoch: 01 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.018 | Train Acc: 99.55% | Train Precision: 73.86% | Train Recall: 34.43% | Train F1-score: 46.75%\n",
            "\t Val. Loss: 0.014 |  Val. Acc: 99.60% | Val. Precision: 86.98% | Val. Recall: 34.75% | Val. F1-score: 49.45%\n",
            "Epoch: 02 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.56% | Train Precision: 74.44% | Train Recall: 35.36% | Train F1-score: 47.74%\n",
            "\t Val. Loss: 0.014 |  Val. Acc: 99.60% | Val. Precision: 87.85% | Val. Recall: 34.22% | Val. F1-score: 49.06%\n",
            "New validation loss 0.01435729614535316 is better than the best validation loss 0.014417269832042397 so far.\n",
            "Epoch: 03 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.57% | Train Precision: 75.78% | Train Recall: 36.65% | Train F1-score: 49.19%\n",
            "\t Val. Loss: 0.014 |  Val. Acc: 99.61% | Val. Precision: 86.76% | Val. Recall: 35.65% | Val. F1-score: 50.34%\n",
            "Epoch: 04 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.57% | Train Precision: 75.49% | Train Recall: 37.23% | Train F1-score: 49.67%\n",
            "\t Val. Loss: 0.014 |  Val. Acc: 99.61% | Val. Precision: 87.40% | Val. Recall: 34.93% | Val. F1-score: 49.73%\n",
            "Epoch: 05 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 76.11% | Train Recall: 38.20% | Train F1-score: 50.66%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 88.18% | Val. Recall: 34.41% | Val. F1-score: 49.30%\n",
            "Epoch: 06 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 76.74% | Train Recall: 38.78% | Train F1-score: 51.32%\n",
            "\t Val. Loss: 0.014 |  Val. Acc: 99.61% | Val. Precision: 87.22% | Val. Recall: 35.77% | Val. F1-score: 50.56%\n",
            "Epoch: 07 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 77.09% | Train Recall: 39.20% | Train F1-score: 51.78%\n",
            "\t Val. Loss: 0.014 |  Val. Acc: 99.61% | Val. Precision: 86.79% | Val. Recall: 36.04% | Val. F1-score: 50.72%\n",
            "Early stopping, on epoch: 7.\n",
            "file  15_64925 (1).pt\n",
            "New validation loss 0.014531296980185586 is better than the best validation loss inf so far.\n",
            "Epoch: 01 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 77.16% | Train Recall: 39.64% | Train F1-score: 52.17%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.61% | Val. Precision: 86.47% | Val. Recall: 36.02% | Val. F1-score: 50.63%\n",
            "Epoch: 02 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 77.57% | Train Recall: 40.28% | Train F1-score: 52.85%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.61% | Val. Precision: 87.71% | Val. Recall: 34.99% | Val. F1-score: 49.84%\n",
            "New validation loss 0.01451239031663195 is better than the best validation loss 0.014531296980185586 so far.\n",
            "Epoch: 03 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 77.63% | Train Recall: 40.43% | Train F1-score: 52.96%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.61% | Val. Precision: 86.71% | Val. Recall: 36.48% | Val. F1-score: 51.16%\n",
            "Epoch: 04 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.60% | Train Precision: 77.95% | Train Recall: 41.16% | Train F1-score: 53.68%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.61% | Val. Precision: 86.65% | Val. Recall: 36.12% | Val. F1-score: 50.78%\n",
            "Epoch: 05 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.014 | Train Acc: 99.60% | Train Precision: 78.18% | Train Recall: 41.43% | Train F1-score: 53.97%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.61% | Val. Precision: 87.64% | Val. Recall: 35.37% | Val. F1-score: 50.18%\n",
            "Epoch: 06 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.014 | Train Acc: 99.60% | Train Precision: 78.38% | Train Recall: 42.08% | Train F1-score: 54.57%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.61% | Val. Precision: 87.44% | Val. Recall: 35.38% | Val. F1-score: 50.17%\n",
            "Epoch: 07 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.014 | Train Acc: 99.60% | Train Precision: 78.75% | Train Recall: 42.30% | Train F1-score: 54.87%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.61% | Val. Precision: 87.72% | Val. Recall: 35.16% | Val. F1-score: 49.98%\n",
            "Early stopping, on epoch: 7.\n",
            "file  16_64925.pt\n",
            "New validation loss 0.014833444344704268 is better than the best validation loss inf so far.\n",
            "Epoch: 01 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.018 | Train Acc: 99.55% | Train Precision: 73.76% | Train Recall: 33.95% | Train F1-score: 46.30%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 88.00% | Val. Recall: 33.56% | Val. F1-score: 48.39%\n",
            "New validation loss 0.014792475311971101 is better than the best validation loss 0.014833444344704268 so far.\n",
            "Epoch: 02 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.56% | Train Precision: 74.51% | Train Recall: 35.20% | Train F1-score: 47.60%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.71% | Val. Recall: 33.99% | Val. F1-score: 48.84%\n",
            "New validation loss 0.014689360998693059 is better than the best validation loss 0.014792475311971101 so far.\n",
            "Epoch: 03 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.56% | Train Precision: 75.22% | Train Recall: 36.20% | Train F1-score: 48.68%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.75% | Val. Recall: 34.26% | Val. F1-score: 49.09%\n",
            "New validation loss 0.014656799191944911 is better than the best validation loss 0.014689360998693059 so far.\n",
            "Epoch: 04 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.57% | Train Precision: 75.65% | Train Recall: 36.99% | Train F1-score: 49.46%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.70% | Val. Recall: 34.57% | Val. F1-score: 49.42%\n",
            "Epoch: 05 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 76.28% | Train Recall: 37.83% | Train F1-score: 50.37%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 88.01% | Val. Recall: 34.21% | Val. F1-score: 49.09%\n",
            "Epoch: 06 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 76.63% | Train Recall: 38.17% | Train F1-score: 50.75%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 86.65% | Val. Recall: 35.36% | Val. F1-score: 50.00%\n",
            "Epoch: 07 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.58% | Train Precision: 77.08% | Train Recall: 38.97% | Train F1-score: 51.58%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 86.40% | Val. Recall: 35.92% | Val. F1-score: 50.53%\n",
            "Epoch: 08 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 77.21% | Train Recall: 39.47% | Train F1-score: 52.06%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 86.81% | Val. Recall: 35.51% | Val. F1-score: 50.24%\n",
            "Early stopping, on epoch: 8.\n",
            "file  17_64925.pt\n",
            "New validation loss 0.014813575612716987 is better than the best validation loss inf so far.\n",
            "Epoch: 01 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.018 | Train Acc: 99.55% | Train Precision: 73.25% | Train Recall: 34.04% | Train F1-score: 46.28%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 88.16% | Val. Recall: 33.41% | Val. F1-score: 48.24%\n",
            "New validation loss 0.014678455318217395 is better than the best validation loss 0.014813575612716987 so far.\n",
            "Epoch: 02 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.56% | Train Precision: 74.34% | Train Recall: 35.03% | Train F1-score: 47.42%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.02% | Val. Recall: 34.98% | Val. F1-score: 49.70%\n",
            "New validation loss 0.014644348993897438 is better than the best validation loss 0.014678455318217395 so far.\n",
            "Epoch: 03 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.57% | Train Precision: 75.24% | Train Recall: 36.35% | Train F1-score: 48.82%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 88.32% | Val. Recall: 33.74% | Val. F1-score: 48.61%\n",
            "Epoch: 04 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.57% | Train Precision: 75.78% | Train Recall: 37.04% | Train F1-score: 49.56%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 88.06% | Val. Recall: 34.05% | Val. F1-score: 48.92%\n",
            "Epoch: 05 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 76.14% | Train Recall: 37.88% | Train F1-score: 50.39%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.78% | Val. Recall: 34.49% | Val. F1-score: 49.34%\n",
            "Epoch: 06 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 76.50% | Train Recall: 38.49% | Train F1-score: 51.01%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 86.84% | Val. Recall: 35.55% | Val. F1-score: 50.27%\n",
            "New validation loss 0.014596368647256835 is better than the best validation loss 0.014644348993897438 so far.\n",
            "Epoch: 07 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.58% | Train Precision: 76.84% | Train Recall: 39.03% | Train F1-score: 51.58%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 86.81% | Val. Recall: 35.62% | Val. F1-score: 50.35%\n",
            "Epoch: 08 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 77.47% | Train Recall: 39.53% | Train F1-score: 52.15%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 86.48% | Val. Recall: 35.93% | Val. F1-score: 50.60%\n",
            "Epoch: 09 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 77.68% | Train Recall: 40.17% | Train F1-score: 52.74%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.35% | Val. Recall: 34.82% | Val. F1-score: 49.60%\n",
            "Epoch: 10 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 77.74% | Train Recall: 40.55% | Train F1-score: 53.10%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.68% | Val. Recall: 34.49% | Val. F1-score: 49.29%\n",
            "Epoch: 11 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.60% | Train Precision: 78.06% | Train Recall: 41.05% | Train F1-score: 53.60%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 86.77% | Val. Recall: 35.70% | Val. F1-score: 50.41%\n",
            "Early stopping, on epoch: 11.\n",
            "file  18_64925.pt\n",
            "New validation loss 0.014781295227222756 is better than the best validation loss inf so far.\n",
            "Epoch: 01 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.018 | Train Acc: 99.55% | Train Precision: 73.44% | Train Recall: 33.99% | Train F1-score: 46.25%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 88.44% | Val. Recall: 33.11% | Val. F1-score: 48.00%\n",
            "New validation loss 0.014732888585231344 is better than the best validation loss 0.014781295227222756 so far.\n",
            "Epoch: 02 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.56% | Train Precision: 74.56% | Train Recall: 35.11% | Train F1-score: 47.51%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 88.39% | Val. Recall: 33.75% | Val. F1-score: 48.62%\n",
            "New validation loss 0.014630518893360114 is better than the best validation loss 0.014732888585231344 so far.\n",
            "Epoch: 03 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.56% | Train Precision: 75.27% | Train Recall: 36.16% | Train F1-score: 48.64%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 88.02% | Val. Recall: 34.18% | Val. F1-score: 49.03%\n",
            "New validation loss 0.01462442558258772 is better than the best validation loss 0.014630518893360114 so far.\n",
            "Epoch: 04 | Epoch Time: 1m 23s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.57% | Train Precision: 75.64% | Train Recall: 36.98% | Train F1-score: 49.47%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.56% | Val. Recall: 34.57% | Val. F1-score: 49.38%\n",
            "New validation loss 0.014535071847380185 is better than the best validation loss 0.01462442558258772 so far.\n",
            "Epoch: 05 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.57% | Train Precision: 76.03% | Train Recall: 37.56% | Train F1-score: 50.08%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.89% | Val. Recall: 34.94% | Val. F1-score: 49.79%\n",
            "Epoch: 06 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 76.47% | Train Recall: 38.14% | Train F1-score: 50.70%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.22% | Val. Recall: 35.35% | Val. F1-score: 50.11%\n",
            "Epoch: 07 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 76.62% | Train Recall: 38.81% | Train F1-score: 51.33%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.55% | Val. Recall: 34.75% | Val. F1-score: 49.56%\n",
            "Epoch: 08 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.58% | Train Precision: 77.00% | Train Recall: 39.36% | Train F1-score: 51.89%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.21% | Val. Recall: 35.26% | Val. F1-score: 50.03%\n",
            "Epoch: 09 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 77.35% | Train Recall: 39.78% | Train F1-score: 52.35%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 86.55% | Val. Recall: 36.11% | Val. F1-score: 50.78%\n",
            "Early stopping, on epoch: 9.\n",
            "file  19_64925.pt\n",
            "New validation loss 0.015199410808501674 is better than the best validation loss inf so far.\n",
            "Epoch: 01 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.018 | Train Acc: 99.56% | Train Precision: 74.01% | Train Recall: 34.04% | Train F1-score: 46.42%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 89.59% | Val. Recall: 32.41% | Val. F1-score: 47.43%\n",
            "New validation loss 0.015053735307005585 is better than the best validation loss 0.015199410808501674 so far.\n",
            "Epoch: 02 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.56% | Train Precision: 74.86% | Train Recall: 35.25% | Train F1-score: 47.71%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 89.56% | Val. Recall: 33.14% | Val. F1-score: 48.21%\n",
            "Epoch: 03 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.57% | Train Precision: 75.52% | Train Recall: 36.11% | Train F1-score: 48.65%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 88.50% | Val. Recall: 34.04% | Val. F1-score: 48.97%\n",
            "New validation loss 0.014967657143219572 is better than the best validation loss 0.015053735307005585 so far.\n",
            "Epoch: 04 | Epoch Time: 1m 26s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 76.29% | Train Recall: 36.94% | Train F1-score: 49.58%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 87.91% | Val. Recall: 34.72% | Val. F1-score: 49.59%\n",
            "Epoch: 05 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 76.73% | Train Recall: 37.86% | Train F1-score: 50.49%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 88.26% | Val. Recall: 34.62% | Val. F1-score: 49.55%\n",
            "Epoch: 06 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.58% | Train Precision: 76.55% | Train Recall: 38.38% | Train F1-score: 50.94%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 87.84% | Val. Recall: 34.50% | Val. F1-score: 49.38%\n",
            "Epoch: 07 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 77.03% | Train Recall: 39.05% | Train F1-score: 51.61%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.59% | Val. Precision: 88.39% | Val. Recall: 34.34% | Val. F1-score: 49.27%\n",
            "Epoch: 08 | Epoch Time: 1m 25s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.59% | Train Precision: 77.23% | Train Recall: 39.18% | Train F1-score: 51.78%\n",
            "\t Val. Loss: 0.015 |  Val. Acc: 99.60% | Val. Precision: 87.37% | Val. Recall: 35.60% | Val. F1-score: 50.37%\n",
            "Early stopping, on epoch: 8.\n",
            "CPU times: user 3h 29min 17s, sys: 2h 15min 33s, total: 5h 44min 51s\n",
            "Wall time: 4h 56min 19s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSBf8rCBeIsK"
      },
      "source": [
        "model = CNN(pretrain, INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_ID)\n",
        "model.load_state_dict(torch.load(model_file_name))\n",
        "model = model.to(device)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YpSzzzt-3Y6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3574ea56-eec7-4e30-f400-dd768f70c707"
      },
      "source": [
        "def load_test(file_path):\n",
        "    vectorized_test_data = torch.load(file_path)\n",
        "    test_data = NYTDataSet(vectorized_data=vectorized_test_data)\n",
        "    return DataLoader(test_data, batch_size=batch_size, collate_fn=pad_sequences)\n",
        "    \n",
        "start_time = time.time()\n",
        "\n",
        "test_file = 'all_test_vect/all_144279.pt'\n",
        "\n",
        "test_loader = load_test(test_file)\n",
        "test_loss, test_acc, test_precision, test_recall, test_f_score = evaluate(model, test_loader, criterion)\n",
        "\n",
        "\n",
        "end_time = time.time()\n",
        "epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "print(f'Epoch: test | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "print(f'\\tTest Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% | ' +\n",
        "      f'Test Precision: {test_precision*100:.2f}% | Test Recall: {test_recall*100:.2f}% | ' +\n",
        "      f'Test F1-score: {test_f_score*100:.2f}%')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: test | Epoch Time: 0m 55s\n",
            "\tTest Loss: 0.015 | Test Acc: 99.60% | Test Precision: 85.20% | Test Recall: 37.38% | Test F1-score: 51.33%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFycOVvUedgE"
      },
      "source": [
        "wandb.run.summary[\"test_acc\"] = test_acc\n",
        "wandb.run.summary[\"test_precision\"] = test_precision\n",
        "wandb.run.summary[\"test_recall\"] = test_recall\n",
        "wandb.run.summary[\"test_f_score\"] = test_f_score\n",
        "\n",
        "run.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "403Del9S4eeW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}