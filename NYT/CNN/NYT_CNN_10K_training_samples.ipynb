{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NYT-CNN 10K training samples",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ecbffbea45614efe92b42e2848408916": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5c3f097b35f54730b96fed1f70becda2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d22c8d9a913a4f64aba6e284796d051d",
              "IPY_MODEL_e6100b1f052b42898d746b728a3447e0"
            ]
          }
        },
        "5c3f097b35f54730b96fed1f70becda2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d22c8d9a913a4f64aba6e284796d051d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_3093857cd1254c7b8a259255d1e35d47",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.03MB of 0.03MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c732791eae144749a484edfd5d929a1"
          }
        },
        "e6100b1f052b42898d746b728a3447e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4e56cf1ffe1a4bb790a22c1507f32799",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bd96989bd97441adacbfe49f2f474528"
          }
        },
        "3093857cd1254c7b8a259255d1e35d47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c732791eae144749a484edfd5d929a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4e56cf1ffe1a4bb790a22c1507f32799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bd96989bd97441adacbfe49f2f474528": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COl-b3Cuj_af",
        "outputId": "40bb91da-be04-4a2d-dea1-105bbda44d6b"
      },
      "source": [
        "!pip install wandb\n",
        "!wandb login\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.10.27)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.1)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.0.2)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.14)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: sentry-sdk>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.5.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (56.0.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.7)\n",
            "Requirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (4.0.0)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkristjan\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi61aWUbEhcK"
      },
      "source": [
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from spacy.lang.en import English\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "import time\n",
        "\n",
        "import wandb\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGaDt3jDFoYt",
        "outputId": "ee6e029c-4c73-4c39-ac3e-b2564f5560d1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/Colab Notebooks/NLP/project/\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Colab Notebooks/NLP/project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRTTJd9_HVzi"
      },
      "source": [
        "# %mkdir NYTData\n",
        "# !wget https://www.dropbox.com/sh/xu9tu5hmjhuddwk/AAD31tK6oEoGlhpRZzeu3Y3Ya/NYTcorpus_train.p.gz?dl=1 --directory-prefix=NYTData\n",
        "# !gunzip -c NYTData/NYTcorpus_train.p.gz\\?dl\\=1 > NYTData/NYTcorpus_train.p"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvyDYMH_JlHR"
      },
      "source": [
        "# %mkdir vector_cache\n",
        "# !wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip --directory-prefix=vector_cache\n",
        "# !unzip vector_cache/wiki-news-300d-1M.vec.zip -d vector_cache/"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUSrOjMIJlN4"
      },
      "source": [
        "PAD = '<PAD>'\n",
        "PAD_ID = 0\n",
        "UNK = '<UNK>'\n",
        "UNK_ID = 1\n",
        "VOCAB_PREFIX = [PAD, UNK]\n",
        "\n",
        "VEC_PATH = Path('vector_cache') / 'wiki-news-300d-1M.vec'\n",
        "DATA_PATH = Path('NYTData')\n",
        "MAX_VOCAB = 25000\n",
        "\n",
        "batch_size = 64\n",
        "validation_split = .3\n",
        "shuffle_dataset = True\n",
        "random_seed = 42"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJx488cqJlPT"
      },
      "source": [
        "class BaseVocab:\n",
        "    def __init__(self, data, lower=False):\n",
        "        self.data = data\n",
        "        self.lower = lower\n",
        "        self.build_vocab()\n",
        "        \n",
        "    def normalize_unit(self, unit):\n",
        "        if self.lower:\n",
        "            return unit.lower()\n",
        "        else:\n",
        "            return unit\n",
        "        \n",
        "    def unit2id(self, unit):\n",
        "        unit = self.normalize_unit(unit)\n",
        "        if unit in self._unit2id:\n",
        "            return self._unit2id[unit]\n",
        "        else:\n",
        "            return self._unit2id[UNK]\n",
        "    \n",
        "    def id2unit(self, id):\n",
        "        return self._id2unit[id]\n",
        "    \n",
        "    def map(self, units):\n",
        "        return [self.unit2id(unit) for unit in units]\n",
        "        \n",
        "    def build_vocab(self):\n",
        "        NotImplementedError()\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self._unit2id)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY-QgWo9JlTj"
      },
      "source": [
        "class PretrainedWordVocab(BaseVocab):\n",
        "    def build_vocab(self):\n",
        "        self._id2unit = VOCAB_PREFIX + self.data\n",
        "        self._unit2id = {w:i for i, w in enumerate(self._id2unit)}"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ar7b46jYJlXC"
      },
      "source": [
        "class LabelVocab(BaseVocab):\n",
        "    def build_vocab(self):\n",
        "        self._id2unit = self.data\n",
        "        self._unit2id = {w:i for i, w in enumerate(self._id2unit)}"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBByipT4L4Kw"
      },
      "source": [
        "class Pretrain:\n",
        "    def __init__(self, vec_filename, max_vocab=-1):\n",
        "        self._vec_filename = vec_filename\n",
        "        self._max_vocab = max_vocab\n",
        "        \n",
        "    @property\n",
        "    def vocab(self):\n",
        "        if not hasattr(self, '_vocab'):\n",
        "            self._vocab, self._emb = self.read()\n",
        "        return self._vocab\n",
        "    \n",
        "    @property\n",
        "    def emb(self):\n",
        "        if not hasattr(self, '_emb'):\n",
        "            self._vocab, self._emb = self.read()\n",
        "        return self._emb\n",
        "        \n",
        "    def read(self):\n",
        "        if self._vec_filename is None:\n",
        "            raise Exception(\"Vector file is not provided.\")\n",
        "        print(f\"Reading pretrained vectors from {self._vec_filename}...\")\n",
        "        \n",
        "        words, emb, failed = self.read_from_file(self._vec_filename, open_func=open)\n",
        "        \n",
        "        if failed > 0: # recover failure\n",
        "            emb = emb[:-failed]\n",
        "        if len(emb) - len(VOCAB_PREFIX) != len(words):\n",
        "            raise Exception(\"Loaded number of vectors does not match number of words.\")\n",
        "            \n",
        "        # Use a fixed vocab size\n",
        "        if self._max_vocab > len(VOCAB_PREFIX) and self._max_vocab < len(words):\n",
        "            words = words[:self._max_vocab - len(VOCAB_PREFIX)]\n",
        "            emb = emb[:self._max_vocab]\n",
        "                \n",
        "        vocab = PretrainedWordVocab(words, lower=True)\n",
        "        print(\"Done Reading\")\n",
        "        \n",
        "        return vocab, emb\n",
        "        \n",
        "    def read_from_file(self, filename, open_func=open):\n",
        "        \"\"\"\n",
        "        Open a vector file using the provided function and read from it.\n",
        "        \"\"\"\n",
        "        first = True\n",
        "        words = []\n",
        "        failed = 0\n",
        "        with open_func(filename, 'rb') as f:\n",
        "            for i, line in enumerate(f):\n",
        "                try:\n",
        "                    line = line.decode()\n",
        "                except UnicodeDecodeError:\n",
        "                    failed += 1\n",
        "                    continue\n",
        "                if first:\n",
        "                    # the first line contains the number of word vectors and the dimensionality\n",
        "                    first = False\n",
        "                    line = line.strip().split(' ')\n",
        "                    rows, cols = [int(x) for x in line]\n",
        "                    emb = np.zeros((rows + len(VOCAB_PREFIX), cols), dtype=np.float32)\n",
        "                    continue\n",
        "\n",
        "                line = line.rstrip().split(' ')\n",
        "                emb[i+len(VOCAB_PREFIX)-1-failed, :] = [float(x) for x in line[-cols:]]\n",
        "                words.append(' '.join(line[:-cols]))\n",
        "        return words, emb, failed"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb7sjmY2nrNv"
      },
      "source": [
        "pretrain = Pretrain(VEC_PATH, MAX_VOCAB)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e0JyfjYL71w"
      },
      "source": [
        "\n",
        "class NYTDataSet(Dataset):\n",
        "    def __init__(self, pretrain, data, label_vocab=None, test=False, n_samples = 10000):\n",
        "        self.pretrain_vocab = pretrain.vocab\n",
        "        self.n_samples = n_samples\n",
        "        self.test = test\n",
        "        self.data = []\n",
        "        \n",
        "        if label_vocab is None:\n",
        "            labels = self.get_labels(data)\n",
        "            self.label_vocab = LabelVocab(labels)\n",
        "        else:\n",
        "            self.label_vocab = label_vocab\n",
        "        \n",
        "        self.load(data)\n",
        "\n",
        "        self.data = sorted(self.data, key=lambda x: len(x[0]), reverse=True)\n",
        "        \n",
        "    def get_labels(self, data):\n",
        "        labels = [a[3:] for a in data]\n",
        "        labels_flattened = []\n",
        "        for label in labels:\n",
        "            labels_flattened.extend(label)\n",
        "        self.labels = list(set(labels_flattened))\n",
        "        return self.labels\n",
        "\n",
        "    def load(self, data):\n",
        "        articles = [a[2] for a in data]\n",
        "        labels = [a[3:] for a in data]\n",
        "        x_train, x_val, y_train, y_val = train_test_split(articles, labels, train_size=self.n_samples, test_size=10000 if self.n_samples > 10000 else self.n_samples, random_state=0)\n",
        "\n",
        "        if self.test:\n",
        "            articles, labels = x_val, y_val\n",
        "            print(f'Using {len(labels)} samples for testing')\n",
        "        else:\n",
        "            articles, labels = x_train, y_train\n",
        "            print(f'Using {len(labels)} samples for testing')\n",
        "\n",
        "        for article, label_words in zip(articles, labels):\n",
        "            tokens = [t.text for t in tokenizer(article)]\n",
        "            text = torch.LongTensor(self.pretrain_vocab.map(tokens))\n",
        "\n",
        "            label_indices = torch.LongTensor(self.label_vocab.map(label_words))\n",
        "\n",
        "            n_labels = len(self.label_vocab)\n",
        "            src = torch.ones(n_labels)\n",
        "            label = torch.zeros(n_labels).scatter_(0, label_indices, src)\n",
        "            label = torch.FloatTensor(label)\n",
        "\n",
        "            self.data.append((text, label))\n",
        "            \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkviEhLmDkf6"
      },
      "source": [
        "def pad_sequences(batch):\n",
        "    max_len = max([len(x[0]) for x in batch])\n",
        "    padded_sequences = torch.zeros((len(batch), max_len), dtype=torch.long)\n",
        "    labels = torch.zeros((len(batch), len(batch[0][1])), dtype=torch.float)\n",
        "    for i, sample in enumerate(batch):\n",
        "\n",
        "      padded_sequences[i, :len(sample[0])] = sample[0]\n",
        "      labels[i, :] = sample[1]\n",
        "\n",
        "    padded_sequences = padded_sequences.to(device)\n",
        "    labels = labels.to(device)\n",
        "    \n",
        "    return padded_sequences, labels"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mY0-pAwpEn4B"
      },
      "source": [
        "pretrain = Pretrain(VEC_PATH, MAX_VOCAB)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3nsAvXhZjkZ",
        "outputId": "989b8fab-848e-4d89-bf7a-4e5f32e0c961"
      },
      "source": [
        "\n",
        "nlp = English()\n",
        "tokenizer = nlp.tokenizer\n",
        "\n",
        "# Check if we are running on a CPU or GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYDGJBkvk7gN",
        "outputId": "04f32f90-dcac-4214-f90b-1a66fbf543d9"
      },
      "source": [
        "%%time \n",
        "training_data_path = DATA_PATH / 'NYTcorpus_train.p'\n",
        "with open(training_data_path, mode='rb') as f:\n",
        "    data = pickle.load(f)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 6.79 s, sys: 4.53 s, total: 11.3 s\n",
            "Wall time: 11.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3IL9y07E1mj",
        "outputId": "f12fcac7-434f-4606-bb1c-14c5f0afccf9"
      },
      "source": [
        "%%time\n",
        "n_training_samples = 10000\n",
        "train_data = NYTDataSet(pretrain, data=data, n_samples=n_training_samples)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using 10000 samples for testing\n",
            "CPU times: user 12min 35s, sys: 11.3 s, total: 12min 47s\n",
            "Wall time: 12min 59s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zh7V_yZPoc9I",
        "outputId": "6c2411e6-72e6-4643-daa1-5d164743c3e2"
      },
      "source": [
        "n_training_samples"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8i8vaorcwan",
        "outputId": "b687cb65-f577-4bdf-f14b-6258125a53b2"
      },
      "source": [
        "%%time\n",
        "test_data = NYTDataSet(pretrain, data, train_data.label_vocab, test=True, n_samples=n_training_samples)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using 10000 samples for testing\n",
            "CPU times: user 12min 51s, sys: 11.7 s, total: 13min 3s\n",
            "Wall time: 13min 17s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_j_JvLHGFtT4"
      },
      "source": [
        "# Creating data indices for training and validation splits:\n",
        "dataset_size = len(train_data)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "if shuffle_dataset:\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8NcPUf6dMz6"
      },
      "source": [
        "train_loader = DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, collate_fn=pad_sequences)\n",
        "validation_loader = DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler, collate_fn=pad_sequences)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, collate_fn=pad_sequences)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI3qkifadUn5"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, pretrain, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
        "                 dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "                \n",
        "        self.embedding = nn.Embedding.from_pretrained(\n",
        "            torch.from_numpy(pretrain.emb), \n",
        "            padding_idx=pad_idx, \n",
        "            freeze=True\n",
        "        )\n",
        "        \n",
        "        self.convs = nn.ModuleList([\n",
        "                                    nn.Conv2d(in_channels = 1, \n",
        "                                              out_channels = n_filters, \n",
        "                                              kernel_size = (fs, embedding_dim)) \n",
        "                                    for fs in filter_sizes\n",
        "                                    ])\n",
        "        \n",
        "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):           \n",
        "        #text = [batch size, sent len]\n",
        "\n",
        "        embedded = self.embedding(text)     \n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "        \n",
        "        embedded = embedded.unsqueeze(1)  \n",
        "        #embedded = [batch size, 1, sent len, emb dim]\n",
        "        \n",
        "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]    \n",
        "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
        "                \n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]     \n",
        "        #pooled_n = [batch size, n_filters]\n",
        "        \n",
        "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
        "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
        "            \n",
        "        return self.fc(cat)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJp7AOCydb6C"
      },
      "source": [
        "INPUT_DIM = len(pretrain.vocab)\n",
        "EMBEDDING_DIM = pretrain.emb.shape[1]\n",
        "N_FILTERS = 100\n",
        "FILTER_SIZES = [3,4,5,6]\n",
        "OUTPUT_DIM = len(train_data.label_vocab)\n",
        "DROPOUT = 0.6\n",
        "\n",
        "model = CNN(pretrain, INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_ID)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ecbffbea45614efe92b42e2848408916",
            "5c3f097b35f54730b96fed1f70becda2",
            "d22c8d9a913a4f64aba6e284796d051d",
            "e6100b1f052b42898d746b728a3447e0",
            "3093857cd1254c7b8a259255d1e35d47",
            "2c732791eae144749a484edfd5d929a1",
            "4e56cf1ffe1a4bb790a22c1507f32799",
            "bd96989bd97441adacbfe49f2f474528"
          ]
        },
        "id": "jYYEkiO8dm7M",
        "outputId": "0a0ec189-3d1a-43e6-cc8c-aae2c2b81897"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "wandb.init(\n",
        "  project=\"NYT Multilabeling\",\n",
        ")\n",
        "# Magic\n",
        "wandb.watch(model)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:2jl8ma3n) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 1511<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ecbffbea45614efe92b42e2848408916",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/drive/My Drive/Colab Notebooks/NLP/project/wandb/run-20210424_171324-2jl8ma3n/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/drive/My Drive/Colab Notebooks/NLP/project/wandb/run-20210424_171324-2jl8ma3n/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>train_loss</td><td>0.01456</td></tr><tr><td>train_precision</td><td>0.79452</td></tr><tr><td>train_f_score</td><td>0.50805</td></tr><tr><td>train_acc</td><td>0.99589</td></tr><tr><td>train_recall</td><td>0.37589</td></tr><tr><td>valid_loss</td><td>0.01984</td></tr><tr><td>valid_acc</td><td>0.99534</td></tr><tr><td>valid_precision</td><td>0.87673</td></tr><tr><td>valid_recall</td><td>0.22019</td></tr><tr><td>valid_f_score</td><td>0.35045</td></tr><tr><td>_runtime</td><td>851</td></tr><tr><td>_timestamp</td><td>1619285258</td></tr><tr><td>_step</td><td>35</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>train_loss</td><td>█▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_precision</td><td>     ▁▁ ▁ ▂ ▃▂▂▃▂▃▃▃▄▄▄ ▅▅▅▆▅▆▆▇▇▇▇█</td></tr><tr><td>train_f_score</td><td>     ▁▁ ▂   ▃▄ ▄ ▅▅▅▅▆▆ ▆▆▆▇▇▇▇▇████</td></tr><tr><td>train_acc</td><td>▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>train_recall</td><td>▁▁▁▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇████</td></tr><tr><td>valid_loss</td><td>██▇▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>valid_acc</td><td>▁▁▁▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇█▇▇▇████</td></tr><tr><td>valid_precision</td><td>  █▅▄▂▃▅▃▃▃▂▃▃▃▂▂▂▃▂▃▃▃▃▂▃▃▂▁▃▃▁▂▂▂▄</td></tr><tr><td>valid_recall</td><td>▁▁▁▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇█▇▇████▇</td></tr><tr><td>valid_f_score</td><td>  ▁▂▂▃▃▃▄▄▅▅▅▅▆▆▆▆▆▇▆▆▇▇▇▇▇▇█▇▇████▇</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">wobbly-sky-7</strong>: <a href=\"https://wandb.ai/kristjan/NYT/runs/2jl8ma3n\" target=\"_blank\">https://wandb.ai/kristjan/NYT/runs/2jl8ma3n</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:2jl8ma3n). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.27<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">usual-water-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/kristjan/NYT%20Multilabeling\" target=\"_blank\">https://wandb.ai/kristjan/NYT%20Multilabeling</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/kristjan/NYT%20Multilabeling/runs/ntrqsilm\" target=\"_blank\">https://wandb.ai/kristjan/NYT%20Multilabeling/runs/ntrqsilm</a><br/>\n",
              "                Run data is saved locally in <code>/content/drive/My Drive/Colab Notebooks/NLP/project/wandb/run-20210424_181038-ntrqsilm</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<wandb.wandb_torch.TorchGraph at 0x7feabd1a7950>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOfidNXRdyty"
      },
      "source": [
        "def multi_label_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    confusion_vector = rounded_preds / y\n",
        "\n",
        "    true_positives = torch.sum(confusion_vector==1)\n",
        "    false_positives = torch.sum(torch.isinf(confusion_vector)) \n",
        "    false_negatives = torch.sum(confusion_vector==0)\n",
        "    true_negatives = torch.sum(torch.isnan(confusion_vector)) \n",
        "\n",
        "    accuracy = (true_positives + true_negatives) / (true_positives + false_positives + false_negatives + true_negatives)\n",
        "    precision = true_positives / (true_positives + false_positives)\n",
        "    recall = true_positives / (true_positives + false_negatives)\n",
        "    f_score = (2 * precision * recall) / (precision + recall)\n",
        "    \n",
        "    return accuracy, precision, recall, f_score"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWjj2IxpeBm0"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    epoch_precision = 0\n",
        "    epoch_recall = 0\n",
        "    epoch_f_score = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(batch[0]).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch[1])\n",
        "        \n",
        "        acc, precision, recall, f_score = multi_label_accuracy(predictions, batch[1])\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        epoch_precision += precision.item()\n",
        "        epoch_recall += recall.item()\n",
        "        epoch_f_score += f_score.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator), \\\n",
        "        epoch_precision / len(iterator), epoch_recall / len(iterator), \\\n",
        "        epoch_f_score / len(iterator)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_Rtg5SHeDcj"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    epoch_precision = 0\n",
        "    epoch_recall = 0\n",
        "    epoch_f_score = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch[0]).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch[1])\n",
        "            \n",
        "            acc, precision, recall, f_score = multi_label_accuracy(predictions, batch[1])\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "            epoch_precision += precision.item()\n",
        "            epoch_recall += recall.item()\n",
        "            epoch_f_score += f_score.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator), \\\n",
        "        epoch_precision / len(iterator), epoch_recall / len(iterator), \\\n",
        "        epoch_f_score / len(iterator)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09eDs6MTeFXT"
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ozh5_0NeHEM",
        "outputId": "e906a352-1413-4507-aa73-b59c4e822307"
      },
      "source": [
        "%%time\n",
        "patience = 7\n",
        "epochs_of_no_improvement = 0\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "wandb.config.early_stopping_patience = patience\n",
        "wandb.config.training_samples=n_training_samples\n",
        "\n",
        "model_file_name = f'nyt_cnn_classifier_trained_with_{n_training_samples}_samples.pt'\n",
        "\n",
        "epoch = 0\n",
        "\n",
        "while True:\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc, train_precision, train_recall, train_f_score \\\n",
        "        = train(model, train_loader, optimizer, criterion)\n",
        "    valid_loss, valid_acc, valid_precision, valid_recall, valid_f_score \\\n",
        "        = evaluate(model, validation_loader, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        print(f'New validation loss {valid_loss} is better than the best validation loss {best_valid_loss} so far.')\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), model_file_name)\n",
        "        epochs_of_no_improvement = 0\n",
        "    else: \n",
        "        epochs_of_no_improvement += 1\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | ' +\n",
        "          f'Train Precision: {train_precision*100:.2f}% | Train Recall: {train_recall*100:.2f}% | ' +\n",
        "          f'Train F1-score: {train_f_score*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% | ' +\n",
        "          f'Val. Precision: {valid_precision*100:.2f}% | Val. Recall: {valid_recall*100:.2f}% | ' +\n",
        "          f'Val. F1-score: {valid_f_score*100:.2f}%')\n",
        "    \n",
        "    wandb.log({\"train_loss\": train_loss, \n",
        "                \"train_precision\": train_precision, \n",
        "                \"train_f_score\": train_f_score, \n",
        "                \"train_acc\": train_acc,\n",
        "                \"train_recall\": train_recall,\n",
        "               \"valid_loss\": valid_loss,\n",
        "               \"valid_acc\": valid_acc,\n",
        "               \"valid_precision\": valid_precision,\n",
        "               \"valid_recall\": valid_recall,\n",
        "               \"valid_f_score\": valid_f_score\n",
        "                })\n",
        "    # check if the training should be stopped and then stop the training\n",
        "    if epochs_of_no_improvement == patience : \n",
        "        print(f'Early stopping, on epoch: {epoch+1}.')\n",
        "        break\n",
        "    epoch += 1\n"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New validation loss 0.030430828240957667 is better than the best validation loss inf so far.\n",
            "Epoch: 01 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.082 | Train Acc: 98.43% | Train Precision: nan% | Train Recall: 1.24% | Train F1-score: nan%\n",
            "\t Val. Loss: 0.030 |  Val. Acc: 99.44% | Val. Precision: nan% | Val. Recall: 0.00% | Val. F1-score: nan%\n",
            "New validation loss 0.029780727751711582 is better than the best validation loss 0.030430828240957667 so far.\n",
            "Epoch: 02 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.031 | Train Acc: 99.44% | Train Precision: nan% | Train Recall: 2.09% | Train F1-score: nan%\n",
            "\t Val. Loss: 0.030 |  Val. Acc: 99.45% | Val. Precision: 100.00% | Val. Recall: 3.03% | Val. F1-score: 5.83%\n",
            "New validation loss 0.029329659773948344 is better than the best validation loss 0.029780727751711582 so far.\n",
            "Epoch: 03 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.030 | Train Acc: 99.44% | Train Precision: nan% | Train Recall: 3.11% | Train F1-score: nan%\n",
            "\t Val. Loss: 0.029 |  Val. Acc: 99.45% | Val. Precision: nan% | Val. Recall: 3.00% | Val. F1-score: nan%\n",
            "New validation loss 0.028584152499729013 is better than the best validation loss 0.029329659773948344 so far.\n",
            "Epoch: 04 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.030 | Train Acc: 99.45% | Train Precision: nan% | Train Recall: 3.48% | Train F1-score: nan%\n",
            "\t Val. Loss: 0.029 |  Val. Acc: 99.45% | Val. Precision: nan% | Val. Recall: 3.01% | Val. F1-score: nan%\n",
            "New validation loss 0.027679994266400946 is better than the best validation loss 0.028584152499729013 so far.\n",
            "Epoch: 05 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.029 | Train Acc: 99.45% | Train Precision: nan% | Train Recall: 4.35% | Train F1-score: nan%\n",
            "\t Val. Loss: 0.028 |  Val. Acc: 99.45% | Val. Precision: nan% | Val. Recall: 3.28% | Val. F1-score: nan%\n",
            "New validation loss 0.02685605504728378 is better than the best validation loss 0.027679994266400946 so far.\n",
            "Epoch: 06 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.028 | Train Acc: 99.45% | Train Precision: 79.57% | Train Recall: 5.95% | Train F1-score: 10.97%\n",
            "\t Val. Loss: 0.027 |  Val. Acc: 99.46% | Val. Precision: 93.51% | Val. Recall: 4.86% | Val. F1-score: 9.18%\n",
            "New validation loss 0.026272598772923997 is better than the best validation loss 0.02685605504728378 so far.\n",
            "Epoch: 07 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.027 | Train Acc: 99.46% | Train Precision: 76.06% | Train Recall: 7.38% | Train F1-score: 13.34%\n",
            "\t Val. Loss: 0.026 |  Val. Acc: 99.46% | Val. Precision: 92.05% | Val. Recall: 5.71% | Val. F1-score: 10.69%\n",
            "New validation loss 0.02570935017726523 is better than the best validation loss 0.026272598772923997 so far.\n",
            "Epoch: 08 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.027 | Train Acc: 99.46% | Train Precision: 72.61% | Train Recall: 8.73% | Train F1-score: 15.45%\n",
            "\t Val. Loss: 0.026 |  Val. Acc: 99.47% | Val. Precision: 88.33% | Val. Recall: 7.19% | Val. F1-score: 13.20%\n",
            "New validation loss 0.025321869179606438 is better than the best validation loss 0.02570935017726523 so far.\n",
            "Epoch: 09 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.026 | Train Acc: 99.46% | Train Precision: 71.91% | Train Recall: 9.87% | Train F1-score: 17.22%\n",
            "\t Val. Loss: 0.025 |  Val. Acc: 99.48% | Val. Precision: 88.46% | Val. Recall: 8.19% | Val. F1-score: 14.87%\n",
            "New validation loss 0.024910530788784333 is better than the best validation loss 0.025321869179606438 so far.\n",
            "Epoch: 10 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.026 | Train Acc: 99.46% | Train Precision: 71.86% | Train Recall: 10.57% | Train F1-score: 18.30%\n",
            "\t Val. Loss: 0.025 |  Val. Acc: 99.48% | Val. Precision: 88.59% | Val. Recall: 8.62% | Val. F1-score: 15.58%\n",
            "New validation loss 0.02448759505406339 is better than the best validation loss 0.024910530788784333 so far.\n",
            "Epoch: 11 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.025 | Train Acc: 99.47% | Train Precision: 74.13% | Train Recall: 11.72% | Train F1-score: 20.09%\n",
            "\t Val. Loss: 0.024 |  Val. Acc: 99.48% | Val. Precision: 86.74% | Val. Recall: 10.02% | Val. F1-score: 17.87%\n",
            "New validation loss 0.02417785492032132 is better than the best validation loss 0.02448759505406339 so far.\n",
            "Epoch: 12 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.025 | Train Acc: 99.47% | Train Precision: 73.13% | Train Recall: 12.33% | Train F1-score: 20.89%\n",
            "\t Val. Loss: 0.024 |  Val. Acc: 99.48% | Val. Precision: 85.42% | Val. Recall: 10.64% | Val. F1-score: 18.85%\n",
            "New validation loss 0.02372724990895454 is better than the best validation loss 0.02417785492032132 so far.\n",
            "Epoch: 13 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.024 | Train Acc: 99.48% | Train Precision: 74.97% | Train Recall: 13.54% | Train F1-score: 22.76%\n",
            "\t Val. Loss: 0.024 |  Val. Acc: 99.49% | Val. Precision: 85.59% | Val. Recall: 11.50% | Val. F1-score: 20.21%\n",
            "New validation loss 0.023373041856796183 is better than the best validation loss 0.02372724990895454 so far.\n",
            "Epoch: 14 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.024 | Train Acc: 99.48% | Train Precision: 73.95% | Train Recall: 14.17% | Train F1-score: 23.62%\n",
            "\t Val. Loss: 0.023 |  Val. Acc: 99.49% | Val. Precision: 81.46% | Val. Recall: 13.39% | Val. F1-score: 22.87%\n",
            "New validation loss 0.023130668683889063 is better than the best validation loss 0.023373041856796183 so far.\n",
            "Epoch: 15 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.023 | Train Acc: 99.48% | Train Precision: 74.89% | Train Recall: 15.27% | Train F1-score: 25.18%\n",
            "\t Val. Loss: 0.023 |  Val. Acc: 99.49% | Val. Precision: 83.71% | Val. Recall: 12.80% | Val. F1-score: 22.10%\n",
            "New validation loss 0.022696550618460837 is better than the best validation loss 0.023130668683889063 so far.\n",
            "Epoch: 16 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.023 | Train Acc: 99.48% | Train Precision: 73.69% | Train Recall: 15.78% | Train F1-score: 25.81%\n",
            "\t Val. Loss: 0.023 |  Val. Acc: 99.50% | Val. Precision: 85.67% | Val. Recall: 13.39% | Val. F1-score: 23.03%\n",
            "New validation loss 0.02251784051669405 is better than the best validation loss 0.022696550618460837 so far.\n",
            "Epoch: 17 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.022 | Train Acc: 99.49% | Train Precision: 74.67% | Train Recall: 17.04% | Train F1-score: 27.54%\n",
            "\t Val. Loss: 0.023 |  Val. Acc: 99.50% | Val. Precision: 84.38% | Val. Recall: 13.85% | Val. F1-score: 23.70%\n",
            "New validation loss 0.022282938215326755 is better than the best validation loss 0.02251784051669405 so far.\n",
            "Epoch: 18 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.022 | Train Acc: 99.49% | Train Precision: 74.27% | Train Recall: 18.05% | Train F1-score: 28.86%\n",
            "\t Val. Loss: 0.022 |  Val. Acc: 99.50% | Val. Precision: 85.48% | Val. Recall: 13.71% | Val. F1-score: 23.51%\n",
            "New validation loss 0.0220002782867944 is better than the best validation loss 0.022282938215326755 so far.\n",
            "Epoch: 19 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.021 | Train Acc: 99.50% | Train Precision: 74.99% | Train Recall: 18.63% | Train F1-score: 29.70%\n",
            "\t Val. Loss: 0.022 |  Val. Acc: 99.50% | Val. Precision: 83.97% | Val. Recall: 14.90% | Val. F1-score: 25.16%\n",
            "New validation loss 0.021792420404071502 is better than the best validation loss 0.0220002782867944 so far.\n",
            "Epoch: 20 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.021 | Train Acc: 99.50% | Train Precision: 74.94% | Train Recall: 19.66% | Train F1-score: 30.90%\n",
            "\t Val. Loss: 0.022 |  Val. Acc: 99.51% | Val. Precision: 83.80% | Val. Recall: 15.49% | Val. F1-score: 26.00%\n",
            "New validation loss 0.021636185176829074 is better than the best validation loss 0.021792420404071502 so far.\n",
            "Epoch: 21 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.020 | Train Acc: 99.50% | Train Precision: 74.44% | Train Recall: 20.54% | Train F1-score: 31.98%\n",
            "\t Val. Loss: 0.022 |  Val. Acc: 99.51% | Val. Precision: 84.35% | Val. Recall: 15.80% | Val. F1-score: 26.47%\n",
            "New validation loss 0.02153772698279391 is better than the best validation loss 0.021636185176829074 so far.\n",
            "Epoch: 22 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.020 | Train Acc: 99.51% | Train Precision: 75.33% | Train Recall: 21.54% | Train F1-score: 33.34%\n",
            "\t Val. Loss: 0.022 |  Val. Acc: 99.51% | Val. Precision: 85.31% | Val. Recall: 15.46% | Val. F1-score: 26.07%\n",
            "New validation loss 0.02131334054184721 is better than the best validation loss 0.02153772698279391 so far.\n",
            "Epoch: 23 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.020 | Train Acc: 99.51% | Train Precision: 75.03% | Train Recall: 22.59% | Train F1-score: 34.50%\n",
            "\t Val. Loss: 0.021 |  Val. Acc: 99.51% | Val. Precision: 83.33% | Val. Recall: 16.31% | Val. F1-score: 27.15%\n",
            "New validation loss 0.021057948529561783 is better than the best validation loss 0.02131334054184721 so far.\n",
            "Epoch: 24 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.019 | Train Acc: 99.52% | Train Precision: 75.34% | Train Recall: 23.05% | Train F1-score: 35.05%\n",
            "\t Val. Loss: 0.021 |  Val. Acc: 99.51% | Val. Precision: 81.83% | Val. Recall: 18.00% | Val. F1-score: 29.31%\n",
            "Epoch: 25 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.019 | Train Acc: 99.52% | Train Precision: 76.16% | Train Recall: 24.31% | Train F1-score: 36.62%\n",
            "\t Val. Loss: 0.021 |  Val. Acc: 99.51% | Val. Precision: 85.65% | Val. Recall: 16.88% | Val. F1-score: 27.97%\n",
            "New validation loss 0.0208540806903484 is better than the best validation loss 0.021057948529561783 so far.\n",
            "Epoch: 26 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.019 | Train Acc: 99.52% | Train Precision: 75.95% | Train Recall: 24.55% | Train F1-score: 36.89%\n",
            "\t Val. Loss: 0.021 |  Val. Acc: 99.52% | Val. Precision: 84.74% | Val. Recall: 17.55% | Val. F1-score: 28.87%\n",
            "New validation loss 0.02061465180459175 is better than the best validation loss 0.0208540806903484 so far.\n",
            "Epoch: 27 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.018 | Train Acc: 99.53% | Train Precision: 75.34% | Train Recall: 25.71% | Train F1-score: 38.14%\n",
            "\t Val. Loss: 0.021 |  Val. Acc: 99.52% | Val. Precision: 84.62% | Val. Recall: 18.64% | Val. F1-score: 30.45%\n",
            "Epoch: 28 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.018 | Train Acc: 99.53% | Train Precision: 76.61% | Train Recall: 26.75% | Train F1-score: 39.38%\n",
            "\t Val. Loss: 0.021 |  Val. Acc: 99.52% | Val. Precision: 85.14% | Val. Recall: 18.28% | Val. F1-score: 29.95%\n",
            "Epoch: 29 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.018 | Train Acc: 99.54% | Train Precision: 77.38% | Train Recall: 27.36% | Train F1-score: 40.22%\n",
            "\t Val. Loss: 0.021 |  Val. Acc: 99.52% | Val. Precision: 87.41% | Val. Recall: 17.66% | Val. F1-score: 29.24%\n",
            "New validation loss 0.020350430656145228 is better than the best validation loss 0.02061465180459175 so far.\n",
            "Epoch: 30 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.54% | Train Precision: 77.60% | Train Recall: 28.46% | Train F1-score: 41.43%\n",
            "\t Val. Loss: 0.020 |  Val. Acc: 99.52% | Val. Precision: 85.26% | Val. Recall: 18.97% | Val. F1-score: 30.87%\n",
            "New validation loss 0.020350084065439852 is better than the best validation loss 0.020350430656145228 so far.\n",
            "Epoch: 31 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.55% | Train Precision: 77.34% | Train Recall: 29.17% | Train F1-score: 42.13%\n",
            "\t Val. Loss: 0.020 |  Val. Acc: 99.52% | Val. Precision: 85.31% | Val. Recall: 19.09% | Val. F1-score: 31.05%\n",
            "Epoch: 32 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.55% | Train Precision: 77.44% | Train Recall: 29.60% | Train F1-score: 42.65%\n",
            "\t Val. Loss: 0.020 |  Val. Acc: 99.52% | Val. Precision: 85.24% | Val. Recall: 19.02% | Val. F1-score: 30.95%\n",
            "New validation loss 0.02029471590797952 is better than the best validation loss 0.020350084065439852 so far.\n",
            "Epoch: 33 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.55% | Train Precision: 77.76% | Train Recall: 30.49% | Train F1-score: 43.60%\n",
            "\t Val. Loss: 0.020 |  Val. Acc: 99.53% | Val. Precision: 84.73% | Val. Recall: 19.77% | Val. F1-score: 31.90%\n",
            "Epoch: 34 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.56% | Train Precision: 78.55% | Train Recall: 31.65% | Train F1-score: 44.97%\n",
            "\t Val. Loss: 0.020 |  Val. Acc: 99.53% | Val. Precision: 85.11% | Val. Recall: 19.49% | Val. F1-score: 31.54%\n",
            "Epoch: 35 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.56% | Train Precision: 78.32% | Train Recall: 32.04% | Train F1-score: 45.26%\n",
            "\t Val. Loss: 0.020 |  Val. Acc: 99.53% | Val. Precision: 84.12% | Val. Recall: 20.30% | Val. F1-score: 32.56%\n",
            "Epoch: 36 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.57% | Train Precision: 78.59% | Train Recall: 33.04% | Train F1-score: 46.31%\n",
            "\t Val. Loss: 0.020 |  Val. Acc: 99.53% | Val. Precision: 84.24% | Val. Recall: 20.52% | Val. F1-score: 32.80%\n",
            "New validation loss 0.02012325827270112 is better than the best validation loss 0.02029471590797952 so far.\n",
            "Epoch: 37 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.57% | Train Precision: 78.70% | Train Recall: 33.86% | Train F1-score: 47.11%\n",
            "\t Val. Loss: 0.020 |  Val. Acc: 99.53% | Val. Precision: 82.70% | Val. Recall: 21.79% | Val. F1-score: 34.41%\n",
            "Epoch: 38 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.57% | Train Precision: 78.57% | Train Recall: 34.44% | Train F1-score: 47.66%\n",
            "\t Val. Loss: 0.020 |  Val. Acc: 99.53% | Val. Precision: 84.55% | Val. Recall: 21.50% | Val. F1-score: 34.11%\n",
            "Epoch: 39 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.58% | Train Precision: 79.44% | Train Recall: 35.66% | Train F1-score: 49.04%\n",
            "\t Val. Loss: 0.020 |  Val. Acc: 99.53% | Val. Precision: 84.71% | Val. Recall: 21.24% | Val. F1-score: 33.83%\n",
            "Epoch: 40 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.58% | Train Precision: 80.03% | Train Recall: 35.90% | Train F1-score: 49.35%\n",
            "\t Val. Loss: 0.020 |  Val. Acc: 99.53% | Val. Precision: 83.12% | Val. Recall: 21.93% | Val. F1-score: 34.53%\n",
            "Epoch: 41 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.014 | Train Acc: 99.59% | Train Precision: 80.06% | Train Recall: 37.07% | Train F1-score: 50.50%\n",
            "\t Val. Loss: 0.021 |  Val. Acc: 99.53% | Val. Precision: 85.29% | Val. Recall: 20.93% | Val. F1-score: 33.48%\n",
            "Epoch: 42 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.014 | Train Acc: 99.59% | Train Precision: 80.39% | Train Recall: 37.42% | Train F1-score: 50.81%\n",
            "\t Val. Loss: 0.020 |  Val. Acc: 99.54% | Val. Precision: 81.96% | Val. Recall: 23.09% | Val. F1-score: 35.86%\n",
            "Epoch: 43 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.014 | Train Acc: 99.59% | Train Precision: 79.94% | Train Recall: 38.22% | Train F1-score: 51.47%\n",
            "\t Val. Loss: 0.020 |  Val. Acc: 99.54% | Val. Precision: 83.51% | Val. Recall: 22.55% | Val. F1-score: 35.31%\n",
            "Epoch: 44 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.014 | Train Acc: 99.60% | Train Precision: 80.56% | Train Recall: 39.05% | Train F1-score: 52.38%\n",
            "\t Val. Loss: 0.020 |  Val. Acc: 99.54% | Val. Precision: 82.16% | Val. Recall: 22.90% | Val. F1-score: 35.61%\n",
            "Early stopping, on epoch: 44.\n",
            "CPU times: user 8min 24s, sys: 4min 44s, total: 13min 8s\n",
            "Wall time: 11min 26s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4rfdX8ztVSi",
        "outputId": "73e0e77c-1687-413f-faa0-793139cdc031"
      },
      "source": [
        "n_training_samples"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSBf8rCBeIsK"
      },
      "source": [
        "model = CNN(pretrain, INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_ID)\n",
        "model.load_state_dict(torch.load(model_file_name))\n",
        "model = model.to(device)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yM3lswCQebhC",
        "outputId": "4bfb1804-d9ad-46dc-ac6a-bd8536e57757"
      },
      "source": [
        "start_time = time.time()\n",
        "test_loss, test_acc, test_precision, test_recall, test_f_score \\\n",
        "    = evaluate(model, test_loader, criterion)\n",
        "end_time = time.time()\n",
        "epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "print(f'Epoch: test | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "print(f'\\tTest Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% | ' +\n",
        "      f'Test Precision: {test_precision*100:.2f}% | Test Recall: {test_recall*100:.2f}% | ' +\n",
        "      f'Test F1-score: {test_f_score*100:.2f}%')"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: test | Epoch Time: 0m 2s\n",
            "\tTest Loss: 0.020 | Test Acc: 99.54% | Test Precision: 84.58% | Test Recall: 23.57% | Test F1-score: 36.32%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFycOVvUedgE"
      },
      "source": [
        ""
      ],
      "execution_count": 106,
      "outputs": []
    }
  ]
}