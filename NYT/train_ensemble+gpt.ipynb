{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JWEh39ZL1p3Z"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sB_ZhA2G2zbP"
   },
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "beVtVqF4hte8"
   },
   "outputs": [],
   "source": [
    "from utils import GPTVectorizedDataset\n",
    "from torch.utils.data import IterableDataset, Dataset, DataLoader, random_split\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import utils\n",
    "import time\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "class ConcatenatingDataset(IterableDataset):\n",
    "    def __init__(self, ensemble_dataset, gpt_dataset, start=0.1, end=1):\n",
    "        super().__init__()\n",
    "#       assert len(ensemble_dataset) == len(gpt_dataset)\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.ensemble_dataset = ensemble_dataset\n",
    "        self.gpt_dataset = gpt_dataset\n",
    "        self.idx = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.gpt_dataset) if len(self.gpt_dataset) < len(self.ensemble_dataset) else len(self.ensemble_dataset)\n",
    "\n",
    "    def __iter__(self):\n",
    "        length = len(self)\n",
    "        start = math.floor(self.start * length)\n",
    "        end = math.floor(self.end * length)\n",
    "        for ensemble_X, gpt in zip(self.ensemble_dataset, self.gpt_dataset):\n",
    "            self.idx += 1\n",
    "            yield torch.cat((ensemble_X, gpt[0]), 0), gpt[1]\n",
    "\n",
    "            \n",
    "class ChunkDataset(IterableDataset):\n",
    "    def __init__(self, file_paths):\n",
    "        super().__init__()\n",
    "        self.file_paths = file_paths\n",
    "        self.total_length = None\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.total_length is not None:\n",
    "            return self.total_length\n",
    "        \n",
    "        self.total_length = 0\n",
    "        for fp in self.file_paths:\n",
    "            print(f'Loading for len {fp}')\n",
    "            self.total_length += len(torch.load(fp).X)\n",
    "            gc.collect()\n",
    "        return self.total_length\n",
    "\n",
    "    def __iter__(self):\n",
    "        for fp in self.file_paths:\n",
    "            print(f'Loading for iter {fp}')\n",
    "            dataset = torch.load(fp)\n",
    "            gc.collect()\n",
    "            if hasattr(dataset, 'y'):\n",
    "                for x, y in zip(dataset.X, dataset.y):\n",
    "                    yield x, y\n",
    "            else:\n",
    "                for x in dataset.X:\n",
    "                    yield x\n",
    "\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "\n",
    "def validation_split(dataset, validation_subset, seed=42):\n",
    "\n",
    "    if validation_subset > 0:\n",
    "        n_total_samples = len(dataset)\n",
    "        n_train_samples = math.floor(n_total_samples * (1-validation_subset))\n",
    "        n_valid_samples = n_total_samples - n_train_samples\n",
    "\n",
    "        train_subset, valid_subset = random_split(\n",
    "            dataset,\n",
    "            [n_train_samples, n_valid_samples],\n",
    "            generator=torch.Generator().manual_seed(seed)\n",
    "        )  # reproducible results\n",
    "\n",
    "    else:\n",
    "        train_subset = dataset\n",
    "        valid_subset = None\n",
    "\n",
    "    return train_subset, valid_subset\n",
    "\n",
    "\n",
    "def multi_label_scores(correct_labels, predicted_labels):\n",
    "\n",
    "    accuracy = accuracy_score(correct_labels, predicted_labels)\n",
    "    precision = precision_score(correct_labels, predicted_labels, average='weighted', zero_division=0)\n",
    "    recall = recall_score(correct_labels, predicted_labels, average='weighted', zero_division=0)\n",
    "    f_1_score = f1_score(correct_labels, predicted_labels, average='weighted', zero_division=0)\n",
    "    \n",
    "    return accuracy, precision, recall, f_1_score\n",
    "\n",
    "def gettags(head_model, features, eval=False):\n",
    "    head_model.eval()\n",
    "    features = features.unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = head_model(features)\n",
    "        multi_label_sigmoids = head_model.act(logits)\n",
    "\n",
    "    preds = multi_label_sigmoids > 0.5\n",
    "    preds = preds.detach().cpu()\n",
    "\n",
    "    return mlb.inverse_transform(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_precision = 0\n",
    "    epoch_recall = 0\n",
    "    epoch_f_score = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "\n",
    "        article_embeddings, labels, idx  = batch\n",
    "        article_embeddings = article_embeddings.to(device)\n",
    "        labels = labels.type(torch.float).to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(article_embeddings)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # calculate metrics\n",
    "        preds = model.act(outputs) > 0.5\n",
    "\n",
    "        acc, precision, recall, f1 = multi_label_scores(labels.detach().cpu(), preds.detach().cpu())\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        epoch_precision += precision.item()\n",
    "        epoch_recall += recall.item()\n",
    "        epoch_f_score += f1.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), \\\n",
    "        epoch_precision / len(iterator), epoch_recall / len(iterator), \\\n",
    "        epoch_f_score / len(iterator)\n",
    "\n",
    "\n",
    "def evaluate(model, iterator, criterion, scheduler=None):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_precision = 0\n",
    "    epoch_recall = 0\n",
    "    epoch_f_score = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            article_embeddings, labels, idx  = batch\n",
    "            article_embeddings = article_embeddings.to(device)\n",
    "            labels = labels.type(torch.float).to(device)\n",
    "\n",
    "            outputs = model(article_embeddings)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # calculate metrics\n",
    "            preds = model.act(outputs) > 0.5\n",
    "\n",
    "            acc, precision, recall, f1 = multi_label_scores(labels.detach().cpu(), preds.detach().cpu())\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_precision += precision.item()\n",
    "            epoch_recall += recall.item()\n",
    "            epoch_f_score += f1.item()\n",
    "            \n",
    "    # lr scheduling\n",
    "    if scheduler:\n",
    "        scheduler.step(epoch_loss / len(iterator))\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), \\\n",
    "        epoch_precision / len(iterator), epoch_recall / len(iterator), \\\n",
    "        epoch_f_score / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sB_ZhA2G2zbP"
   },
   "source": [
    "## Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "lxaAq4SJTmmZ"
   },
   "outputs": [],
   "source": [
    "gpt_vectorized_chunks_path = Path('/gpfs/space/projects/stud_nlp_share/cutoff/GPT/vectorized/train')\n",
    "gpt_file_paths = os.listdir(gpt_vectorized_chunks_path)\n",
    "sorted_gpt_filenames = sorted(gpt_file_paths, key=lambda fn: int(fn.split('chunk')[1].split('of')[0]))\n",
    "sorted_gpt_filepaths = [gpt_vectorized_chunks_path / Path(p) for p in sorted_gpt_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "BOKl3tDudyhU"
   },
   "outputs": [],
   "source": [
    "ensemble_vectorized_chunks_path = '/gpfs/space/projects/stud_nlp_share/cutoff/ensemble/vectorized/train'\n",
    "ensemble_file_paths = os.listdir(ensemble_vectorized_chunks_path)\n",
    "sorted_ensemble_filenames = sorted(ensemble_file_paths, key=lambda fn: int(fn.split('chunk')[1].split('of')[0]))\n",
    "sorted_ensemble_filepaths = [ensemble_vectorized_chunks_path / Path(p) for p in sorted_ensemble_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_1195k_min500_cutoff_replace_chunk1of4.pt',\n",
       " 'train_1195k_min500_cutoff_replace_chunk2of4.pt',\n",
       " 'train_1195k_min500_cutoff_replace_chunk3of4.pt',\n",
       " 'train_1195k_min500_cutoff_replace_chunk4of4.pt']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_gpt_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "nf7jKT4ZeA6k"
   },
   "outputs": [],
   "source": [
    "ensemble_dataset = ChunkDataset(sorted_ensemble_filepaths)\n",
    "gpt_dataset_first_chunk = ChunkDataset(sorted_gpt_filepaths)\n",
    "\n",
    "concat_dataset = ConcatenatingDataset(ensemble_dataset, gpt_dataset_first_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading for len /gpfs/space/projects/stud_nlp_share/cutoff/GPT/vectorized/train/train_1195k_min500_cutoff_replace_chunk1of4.pt\n",
      "Loading for len /gpfs/space/projects/stud_nlp_share/cutoff/GPT/vectorized/train/train_1195k_min500_cutoff_replace_chunk2of4.pt\n",
      "Loading for len /gpfs/space/projects/stud_nlp_share/cutoff/GPT/vectorized/train/train_1195k_min500_cutoff_replace_chunk3of4.pt\n",
      "Loading for len /gpfs/space/projects/stud_nlp_share/cutoff/GPT/vectorized/train/train_1195k_min500_cutoff_replace_chunk4of4.pt\n",
      "Loading for len /gpfs/space/projects/stud_nlp_share/cutoff/ensemble/vectorized/train/ensemble_vect_train_chunk1of24.pt\n",
      "Loading for len /gpfs/space/projects/stud_nlp_share/cutoff/ensemble/vectorized/train/ensemble_vect_train_chunk2of24.pt\n",
      "Loading for len /gpfs/space/projects/stud_nlp_share/cutoff/ensemble/vectorized/train/ensemble_vect_train_chunk3of24.pt\n",
      "Loading for len /gpfs/space/projects/stud_nlp_share/cutoff/ensemble/vectorized/train/ensemble_vect_train_chunk4of24.pt\n",
      "Loading for len /gpfs/space/projects/stud_nlp_share/cutoff/ensemble/vectorized/train/ensemble_vect_train_chunk5of24.pt\n",
      "Loading for len /gpfs/space/projects/stud_nlp_share/cutoff/ensemble/vectorized/train/ensemble_vect_train_chunk6of24.pt\n",
      "Loading for len /gpfs/space/projects/stud_nlp_share/cutoff/ensemble/vectorized/train/ensemble_vect_train_chunk7of24.pt\n",
      "Loading for len /gpfs/space/projects/stud_nlp_share/cutoff/ensemble/vectorized/train/ensemble_vect_train_chunk8of24.pt\n",
      "Loading for len /gpfs/space/projects/stud_nlp_share/cutoff/ensemble/vectorized/train/ensemble_vect_train_chunk9of24.pt\n",
      "Loading for len /gpfs/space/projects/stud_nlp_share/cutoff/ensemble/vectorized/train/ensemble_vect_train_chunk10of24.pt\n",
      "Loading for len /gpfs/space/projects/stud_nlp_share/cutoff/ensemble/vectorized/train/ensemble_vect_train_chunk11of24.pt\n",
      "Loading for len /gpfs/space/projects/stud_nlp_share/cutoff/ensemble/vectorized/train/ensemble_vect_train_chunk12of24.pt\n",
      "Loading for len /gpfs/space/projects/stud_nlp_share/cutoff/ensemble/vectorized/train/ensemble_vect_train_chunk13of24.pt\n",
      "Loading for len /gpfs/space/projects/stud_nlp_share/cutoff/ensemble/vectorized/train/ensemble_vect_train_chunk14of24.pt\n",
      "Loading for len /gpfs/space/projects/stud_nlp_share/cutoff/ensemble/vectorized/train/ensemble_vect_train_chunk15of24.pt\n",
      "Loading for len /gpfs/space/projects/stud_nlp_share/cutoff/ensemble/vectorized/train/ensemble_vect_train_chunk16of24.pt\n",
      "Loading for len /gpfs/space/projects/stud_nlp_share/cutoff/ensemble/vectorized/train/ensemble_vect_train_chunk17of24.pt\n",
      "Loading for len /gpfs/space/projects/stud_nlp_share/cutoff/ensemble/vectorized/train/ensemble_vect_train_chunk18of24.pt\n",
      "Loading for len /gpfs/space/projects/stud_nlp_share/cutoff/ensemble/vectorized/train/ensemble_vect_train_chunk19of24.pt\n",
      "Loading for len /gpfs/space/projects/stud_nlp_share/cutoff/ensemble/vectorized/train/ensemble_vect_train_chunk20of24.pt\n",
      "Loading for len /gpfs/space/projects/stud_nlp_share/cutoff/ensemble/vectorized/train/ensemble_vect_train_chunk21of24.pt\n",
      "Loading for len /gpfs/space/projects/stud_nlp_share/cutoff/ensemble/vectorized/train/ensemble_vect_train_chunk22of24.pt\n",
      "Loading for len /gpfs/space/projects/stud_nlp_share/cutoff/ensemble/vectorized/train/ensemble_vect_train_chunk23of24.pt\n",
      "Loading for len /gpfs/space/projects/stud_nlp_share/cutoff/ensemble/vectorized/train/ensemble_vect_train_chunk24of24.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1195938"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting train/validation\n",
    "batch_size = 256\n",
    "seed = 42\n",
    "\n",
    "train_subset, valid_subset = validation_split(concat_dataset, 0.1, seed)\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_subset, batch_size=batch_size)\n",
    "\n",
    "n_training_samples = len(concat_dataset)\n",
    "n_training_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4205"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading for iter /gpfs/space/projects/stud_nlp_share/cutoff/ensemble/vectorized/train/ensemble_vect_train_chunk1of24.pt\n",
      "Loading for iter /gpfs/space/projects/stud_nlp_share/cutoff/GPT/vectorized/train/train_1195k_min500_cutoff_replace_chunk1of4.pt\n"
     ]
    }
   ],
   "source": [
    "for i in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeadClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim, num_classes=538):\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.lin1 = nn.Linear(hidden_dim, 1600)\n",
    "        self.lin2 = nn.Linear(1600, 900)\n",
    "        self.lin3 = nn.Linear(900, num_classes)\n",
    "        \n",
    "        self.act = nn.Sigmoid()  # used manually after `forward()` to compute preds/accuracies\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.lin1(inputs))\n",
    "        x = self.relu(self.lin2(inputs))\n",
    "        x = self.relu(self.lin3(inputs))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1n35dz8o) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 15453<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14e371d3d72a475eb6175979443624a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/gpfs/space/home/mykyta/nlp/ut-mit-news-classify/NYT/wandb/run-20210524_204228-1n35dz8o/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/gpfs/space/home/mykyta/nlp/ut-mit-news-classify/NYT/wandb/run-20210524_204228-1n35dz8o/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">pretty-resonance-9</strong>: <a href=\"https://wandb.ai/ut-mit-news-classify/ensemble-plus-gpt2/runs/1n35dz8o\" target=\"_blank\">https://wandb.ai/ut-mit-news-classify/ensemble-plus-gpt2/runs/1n35dz8o</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:1n35dz8o). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.30<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">pleasant-bee-10</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ut-mit-news-classify/ensemble-plus-gpt2\" target=\"_blank\">https://wandb.ai/ut-mit-news-classify/ensemble-plus-gpt2</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ut-mit-news-classify/ensemble-plus-gpt2/runs/2psf5ylr\" target=\"_blank\">https://wandb.ai/ut-mit-news-classify/ensemble-plus-gpt2/runs/2psf5ylr</a><br/>\n",
       "                Run data is saved locally in <code>/gpfs/space/home/mykyta/nlp/ut-mit-news-classify/NYT/wandb/run-20210524_205106-2psf5ylr</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# Start a new run\n",
    "run = wandb.init(project='ensemble-plus-gpt2', entity='ut-mit-news-classify')\n",
    "\n",
    "#hyperparams\n",
    "epochs = 200\n",
    "patience = 50\n",
    "# `batch_size` is defined earlier\n",
    "# `seed` is defined earlier\n",
    "learning_rate = 1e-3\n",
    "validation_split = 0.1\n",
    "\n",
    "# reduce learning rate callback params\n",
    "factor = 0.2\n",
    "reduce_lr_patience = 5\n",
    "min_lr = 1e-6\n",
    "\n",
    "# Save hyperparameters\n",
    "config = wandb.config\n",
    "config.batch_size = batch_size\n",
    "config.epochs = epochs\n",
    "config.early_stopping_patience = patience\n",
    "config.learning_rate = learning_rate\n",
    "config.validation_split = validation_split\n",
    "\n",
    "config.reduce_lr = f'fac{factor}_patience{reduce_lr_patience}_min_lr{min_lr}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-ded3ab2aad61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_f_score\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_f_score\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-623b713e735b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0marticle_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp/lib/python3.8/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp/lib/python3.8/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT_co\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Dataset[T_co]'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'ConcatDataset[T_co]'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model\n",
    "model = HeadClassifier(1768, 538).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                    lr = 5e-1, # default is 5e-5, our notebook had 2e-5\n",
    "                  )\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=factor, patience=reduce_lr_patience, min_lr=min_lr, verbose=True)\n",
    "\n",
    "# training\n",
    "epochs_of_no_improvement = 0\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "best_val_loss_model_filename = 'models/ensemble-gpt-vectors-with-filtered-and-cut-off-ends-full.h5'\n",
    "wandb.save(best_val_loss_model_filename)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc, train_precision, train_recall, train_f_score \\\n",
    "        = train(model, train_loader, optimizer, criterion)\n",
    "    valid_loss, valid_acc, valid_precision, valid_recall, valid_f_score \\\n",
    "        = evaluate(model, valid_loader, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        print(f'New validation loss {valid_loss} is better than the best validation loss {best_valid_loss} so far.')\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model, best_val_loss_model_filename)\n",
    "        epochs_of_no_improvement = 0\n",
    "    else: \n",
    "        epochs_of_no_improvement += 1\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | ' +\n",
    "          f'Train Precision: {train_precision*100:.2f}% | Train Recall: {train_recall*100:.2f}% | ' +\n",
    "          f'Train F1-score: {train_f_score*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% | ' +\n",
    "          f'Val. Precision: {valid_precision*100:.2f}% | Val. Recall: {valid_recall*100:.2f}% | ' +\n",
    "          f'Val. F1-score: {valid_f_score*100:.2f}%')\n",
    "    \n",
    "    wandb.log({\"train_loss\": train_loss, \n",
    "                \"train_precision\": train_precision, \n",
    "                \"train_f_score\": train_f_score, \n",
    "                \"train_acc\": train_acc,\n",
    "                \"train_recall\": train_recall,\n",
    "               \"valid_loss\": valid_loss,\n",
    "               \"valid_acc\": valid_acc,\n",
    "               \"valid_precision\": valid_precision,\n",
    "               \"valid_recall\": valid_recall,\n",
    "               \"valid_f_score\": valid_f_score,\n",
    "               \"epoch\": epoch+1,\n",
    "                })\n",
    "    # check if the training should be stopped and then stop the training\n",
    "    if epochs_of_no_improvement == patience : \n",
    "        print(f'Early stopping, on epoch: {epoch+1}.')\n",
    "        break\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on test (same wandb run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "lxaAq4SJTmmZ"
   },
   "outputs": [],
   "source": [
    "gpt_vectorized_chunks_path = Path('/gpfs/space/projects/stud_nlp_share/cutoff/GPT/vectorized/test')\n",
    "gpt_file_paths = os.listdir(gpt_vectorized_chunks_path)\n",
    "sorted_gpt_filenames = sorted(gpt_file_paths, key=lambda fn: int(fn.split('chunk')[1].split('of')[0]))\n",
    "sorted_gpt_filepaths = [gpt_vectorized_chunks_path / Path(p) for p in sorted_gpt_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "BOKl3tDudyhU"
   },
   "outputs": [],
   "source": [
    "ensemble_vectorized_chunks_path = '/gpfs/space/projects/stud_nlp_share/cutoff/ensemble/vectorized/test'\n",
    "ensemble_file_paths = os.listdir(ensemble_vectorized_chunks_path)\n",
    "sorted_ensemble_filenames = sorted(ensemble_file_paths, key=lambda fn: int(fn.split('chunk')[1].split('of')[0]))\n",
    "sorted_ensemble_filepaths = [ensemble_vectorized_chunks_path / Path(p) for p in sorted_ensemble_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "nf7jKT4ZeA6k"
   },
   "outputs": [],
   "source": [
    "test_ensemble_dataset = ChunkDataset(sorted_ensemble_filepaths)\n",
    "test_gpt_dataset = ChunkDataset(sorted_gpt_filepaths)\n",
    "\n",
    "test_dataset = ConcatenatingDataset(test_ensemble_dataset, test_gpt_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading for len /gpfs/space/projects/stud_nlp_share/cutoff/GPT/vectorized/test/test_1195k_min500_cutoff_replace_chunk1of4.pt\n",
      "Loading for len /gpfs/space/projects/stud_nlp_share/cutoff/GPT/vectorized/test/test_1195k_min500_cutoff_replace_chunk2of4.pt\n",
      "Loading for len /gpfs/space/projects/stud_nlp_share/cutoff/GPT/vectorized/test/test_1195k_min500_cutoff_replace_chunk3of4.pt\n",
      "Loading for len /gpfs/space/projects/stud_nlp_share/cutoff/GPT/vectorized/test/test_1195k_min500_cutoff_replace_chunk4of4.pt\n",
      "Loading for len /gpfs/space/projects/stud_nlp_share/cutoff/ensemble/vectorized/test/ensemble_vect_test_chunk1of3.pt\n",
      "Loading for len /gpfs/space/projects/stud_nlp_share/cutoff/ensemble/vectorized/test/ensemble_vect_test_chunk2of3.pt\n",
      "Loading for len /gpfs/space/projects/stud_nlp_share/cutoff/ensemble/vectorized/test/ensemble_vect_test_chunk3of3.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "133032"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model on the test set\n",
    "\n",
    "test_model = torch.load(best_val_loss_model_filename)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "start_time = time.time()\n",
    "test_loss, test_acc, test_precision, test_recall, test_f_score \\\n",
    "    = evaluate(test_model, test_loader, criterion)\n",
    "end_time = time.time()\n",
    "epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "wandb.run.summary[f'test_acc'] = test_acc\n",
    "wandb.run.summary[f'test_precision'] = test_precision\n",
    "wandb.run.summary[f'test_recall'] = test_recall\n",
    "wandb.run.summary[f'test_f_score'] = test_f_score\n",
    "\n",
    "print(f'Epoch: test | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "print(f'\\tTest Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% | ' +\n",
    "      f'Test Precision: {test_precision*100:.2f}% | Test Recall: {test_recall*100:.2f}% | ' +\n",
    "      f'Test F1-score: {test_f_score*100:.2f}%')\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOdOr9Y36j8Z"
   },
   "source": [
    "# Save model to Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VbGcydaR-3tH",
    "outputId": "6ef5d363-4a5e-4f79-b8c8-f8174a94819c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wandb.sdk.wandb_artifacts.Artifact at 0x7f7dd9f269d0>"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifact = wandb.Artifact('ensemble-plus-gpt2-bigger-layers-full-train', type='keras-model')\n",
    "artifact.add_file(best_val_loss_model_filename)\n",
    "run.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMenWG9W6qVA"
   },
   "source": [
    "# Load model and test on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "4f5d7cae934f42998e3d8ea7ef1221aa",
      "a4e97c9290b44630989867d93e6da418",
      "c3f8ca29aeea4b6fb9ace2db3531644d",
      "744d85c274b341689158b0e628f5bd96",
      "a701e636eb3f44d6bc25558c4446a5c5",
      "2fa8997adf554bb19afcfb3c56f6c2c1",
      "24ea6ffe58bf4860979e0e77d92ef7dc",
      "a6fe1cd11588432397e9cbe50d7b20ac"
     ]
    },
    "id": "28ZIvUxtaRSP",
    "outputId": "eace2aec-8a60-4c59-a22d-61ca2faef187"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 1624<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5d7cae934f42998e3d8ea7ef1221aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 96.71MB of 96.71MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/content/drive/My Drive/Colab Notebooks/NLP/project/wandb/run-20210521_164650-s1otbc0r/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/content/drive/My Drive/Colab Notebooks/NLP/project/wandb/run-20210521_164650-s1otbc0r/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>145</td></tr><tr><td>loss</td><td>0.00742</td></tr><tr><td>accuracy</td><td>0.53805</td></tr><tr><td>recall</td><td>0.68013</td></tr><tr><td>precision</td><td>0.84985</td></tr><tr><td>f1</td><td>0.75536</td></tr><tr><td>val_loss</td><td>0.00855</td></tr><tr><td>val_accuracy</td><td>0.52053</td></tr><tr><td>val_recall</td><td>0.64804</td></tr><tr><td>val_precision</td><td>0.82058</td></tr><tr><td>val_f1</td><td>0.72396</td></tr><tr><td>lr</td><td>1e-05</td></tr><tr><td>_runtime</td><td>3569</td></tr><tr><td>_timestamp</td><td>1621619179</td></tr><tr><td>_step</td><td>150</td></tr><tr><td>best_val_loss</td><td>0.0085</td></tr><tr><td>best_epoch</td><td>95</td></tr><tr><td>test_precision_weighted</td><td>0.76914</td></tr><tr><td>test_f1_weighted</td><td>0.67385</td></tr><tr><td>test_recall_weighted</td><td>0.61145</td></tr><tr><td>test_precision_micro</td><td>0.78765</td></tr><tr><td>test_f1_micro</td><td>0.68845</td></tr><tr><td>test_recall_micro</td><td>0.61145</td></tr><tr><td>test_precision_macro</td><td>0.70639</td></tr><tr><td>test_f1_macro</td><td>0.5688</td></tr><tr><td>test_recall_macro</td><td>0.49108</td></tr><tr><td>test_precision_samples</td><td>0.78976</td></tr><tr><td>test_f1_samples</td><td>0.70229</td></tr><tr><td>test_recall_samples</td><td>0.69372</td></tr><tr><td>test_accuracy</td><td>0.36502</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▄▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>accuracy</td><td>▃█▇▆▅▄▃▃▂▂▂▂▂▂▂▂▂▁▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃</td></tr><tr><td>recall</td><td>▁▄▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>precision</td><td>█▃▂▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆</td></tr><tr><td>f1</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>val_loss</td><td>█▄▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▆█▇▇▇█▇▆▅▅▄▅▄▃▄▃▃▃▃▂▃▄▃▃▄▅▆▁▄▅▅▅▃▄▆▃▄▂▂▁</td></tr><tr><td>val_recall</td><td>▁▄▆▆▇▇▇▇▇▇▇█▇▇█▇██▇█▇██▇████████████████</td></tr><tr><td>val_precision</td><td>█▅▅▄▂▄▄▃▄▄▄▃▄▄▃▄▂▃▄▂▃▂▃▃▂▃▁▃▃▃▃▁▂▂▁▃▂▃▃▂</td></tr><tr><td>val_f1</td><td>▁▅▆▇▇▇▇██▇██████████████████████████████</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>test_precision_weighted</td><td>▁</td></tr><tr><td>test_f1_weighted</td><td>▁</td></tr><tr><td>test_recall_weighted</td><td>▁</td></tr><tr><td>test_precision_micro</td><td>▁</td></tr><tr><td>test_f1_micro</td><td>▁</td></tr><tr><td>test_recall_micro</td><td>▁</td></tr><tr><td>test_precision_macro</td><td>▁</td></tr><tr><td>test_f1_macro</td><td>▁</td></tr><tr><td>test_recall_macro</td><td>▁</td></tr><tr><td>test_precision_samples</td><td>▁</td></tr><tr><td>test_f1_samples</td><td>▁</td></tr><tr><td>test_recall_samples</td><td>▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">major-planet-5</strong>: <a href=\"https://wandb.ai/ut-mit-news-classify/ensemble-plus-gpt2/runs/s1otbc0r\" target=\"_blank\">https://wandb.ai/ut-mit-news-classify/ensemble-plus-gpt2/runs/s1otbc0r</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "Dv8Va6EkoahM",
    "outputId": "6d79514b-d4ce-45f6-87d8-0ef8c93a038a"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-db6df086aa74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mtext_X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text_X' is not defined"
     ]
    }
   ],
   "source": [
    "del test_y\n",
    "del test_X\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UtYU1CW3zQUE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "train on ensemble+gpt preprocesses vectors",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python (nlp)",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05f7fd45ba6e4ddc97d31046cab71c64": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "24ea6ffe58bf4860979e0e77d92ef7dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2fa8997adf554bb19afcfb3c56f6c2c1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b604b9b25ec421198f3e5cc0d132272": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4f5d7cae934f42998e3d8ea7ef1221aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c3f8ca29aeea4b6fb9ace2db3531644d",
       "IPY_MODEL_744d85c274b341689158b0e628f5bd96"
      ],
      "layout": "IPY_MODEL_a4e97c9290b44630989867d93e6da418"
     }
    },
    "567a85f741864da0a06c3289f294e77a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "593f0b878aef4eebaa03fa91354dea09": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9e831635b9674a4698106d79b7556cf4",
       "IPY_MODEL_b253caff5f6345b8a002a979f5da3adc"
      ],
      "layout": "IPY_MODEL_7e34e97fc84643f3bbcc3ffce55e0622"
     }
    },
    "5d8f52cf57984e6dac2de9553a3877e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "744d85c274b341689158b0e628f5bd96": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a6fe1cd11588432397e9cbe50d7b20ac",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_24ea6ffe58bf4860979e0e77d92ef7dc",
      "value": 1
     }
    },
    "7e34e97fc84643f3bbcc3ffce55e0622": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "89fac9f84e5748e791d93965b7ac5655": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b8cd82ad8ac647cca4256a82aedd39b4",
       "IPY_MODEL_e4fcedfbf8ea4901b4c2a5807e7c4582"
      ],
      "layout": "IPY_MODEL_c419b8c3aef344c39c182f9d134757a7"
     }
    },
    "9965e7eb421542f4850af954351372cc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e831635b9674a4698106d79b7556cf4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f2fbd82618484b8bb3f193600cffa6aa",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_567a85f741864da0a06c3289f294e77a",
      "value": 3
     }
    },
    "9e94792121f140adaa4e41e739b1e61b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4e97c9290b44630989867d93e6da418": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6fe1cd11588432397e9cbe50d7b20ac": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a701e636eb3f44d6bc25558c4446a5c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b253caff5f6345b8a002a979f5da3adc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e94792121f140adaa4e41e739b1e61b",
      "placeholder": "​",
      "style": "IPY_MODEL_05f7fd45ba6e4ddc97d31046cab71c64",
      "value": " 3/3 [00:17&lt;00:00,  5.90s/it]"
     }
    },
    "b8cd82ad8ac647cca4256a82aedd39b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f299754715a9478884249e3459bfea1b",
      "placeholder": "​",
      "style": "IPY_MODEL_5d8f52cf57984e6dac2de9553a3877e5",
      "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r"
     }
    },
    "c3f8ca29aeea4b6fb9ace2db3531644d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2fa8997adf554bb19afcfb3c56f6c2c1",
      "placeholder": "​",
      "style": "IPY_MODEL_a701e636eb3f44d6bc25558c4446a5c5",
      "value": " 96.72MB of 96.72MB uploaded (0.00MB deduped)\r"
     }
    },
    "c419b8c3aef344c39c182f9d134757a7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4fcedfbf8ea4901b4c2a5807e7c4582": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9965e7eb421542f4850af954351372cc",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4b604b9b25ec421198f3e5cc0d132272",
      "value": 1
     }
    },
    "f299754715a9478884249e3459bfea1b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2fbd82618484b8bb3f193600cffa6aa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
