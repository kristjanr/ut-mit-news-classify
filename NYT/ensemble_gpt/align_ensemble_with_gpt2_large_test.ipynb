{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train on ensemble+gpt preprocesses vectors",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python380jvsc74a57bd01d47407f50cb4f57b03fc08e1f31d8212463fce5635b845e385eb7c9dcc614a7",
      "display_name": "Python 3.8.0 64-bit ('nlp': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2888fe3a64224cc6b67fbc855f0f0e89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_40b85a686d814512958520d1a1a326c9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e2b93c9cc95d42f39ea4202162c92c70",
              "IPY_MODEL_dfda9ecb01d2454cb112a9e2659b360b"
            ]
          }
        },
        "40b85a686d814512958520d1a1a326c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2b93c9cc95d42f39ea4202162c92c70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_fef96ae5bd5547aaac0044ba91969847",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 96.72MB of 96.72MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bf5c16d1b9b6461b80ab9b896bc80a30"
          }
        },
        "dfda9ecb01d2454cb112a9e2659b360b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_75622757a53c458899c0979235ec7b1e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9f456137ce404b5790155c58c6fc864e"
          }
        },
        "fef96ae5bd5547aaac0044ba91969847": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bf5c16d1b9b6461b80ab9b896bc80a30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "75622757a53c458899c0979235ec7b1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9f456137ce404b5790155c58c6fc864e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "source": [
        "# Description\n",
        "\n",
        "This notebook takes as input:\n",
        "\n",
        "**ensemble** chunks (EmbeddedDataset):\n",
        "- non-filtered\n",
        "- non-shuffled\n",
        "\n",
        "**gpt2-large** chunks (GPTEmbeddedDataset):\n",
        "- non-filtered\n",
        "- shuffled (seed 42)\n",
        "\n",
        "And outputs the following *single-file whole datasets*:\n",
        "\n",
        "**ensemble** (EmbeddedDataset):\n",
        "- filtered\n",
        "- shuffled (seed 42)\n",
        "\n",
        "**gpt2-large** (EmbeddedDataset):\n",
        "- filtered\n",
        "- shuffled (seed 42)\n",
        "\n",
        "Along the way it verifies:\n",
        "- properties of the *input* chunks claimed above\n",
        "- alignment of *ensemble* and *gpt2-large* articles by comparing their labelsets"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "# Definitions"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beVtVqF4hte8"
      },
      "source": [
        "from torch.utils.data import IterableDataset, Dataset, DataLoader\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "from pathlib import Path\n",
        "import gc\n",
        "import numpy as np\n",
        "from tqdm.autonotebook import tqdm\n",
        "import random\n",
        "\n",
        "module_path = \"/home/mbaliesnyi/code/nlp-project/ut-mit-news-classify/NYT\"\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "import utils"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils import vec2labels\n",
        "\n",
        "class GPTEmbeddedDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx], idx\n",
        "\n",
        "\n",
        "class EmbeddedDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx], idx\n",
        "\n",
        "\n",
        "class ChunkMixDataset(Dataset):\n",
        "    def __init__(self, file_paths):\n",
        "        self.file_paths = file_paths\n",
        "        self.X = None\n",
        "        self.y = None\n",
        "        self._load()\n",
        "\n",
        "    def _load(self):\n",
        "        '''Load & concatenate chunks defined in `self.file_paths`. \n",
        "        Convert vectorized labels to strings.'''\n",
        "\n",
        "        print(f'Loading {len(self.file_paths)} chunks')\n",
        "\n",
        "        for fp in tqdm(self.file_paths):\n",
        "            dataset = torch.load(fp)\n",
        "\n",
        "            if self.X is None:\n",
        "                self.X = dataset.X\n",
        "            else:\n",
        "                self.X = torch.vstack((self.X, dataset.X))\n",
        "\n",
        "            if hasattr(dataset, 'y'):\n",
        "                if self.y is None:\n",
        "                    self.y = vec2labels(dataset.y)\n",
        "                else:\n",
        "                    self.y += vec2labels(dataset.y)\n",
        "            del dataset\n",
        "            gc.collect()\n",
        "\n",
        "        print(f'Loaded all chunks. Total length: {len(self)}.')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __item__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ]
    },
    {
      "source": [
        "# Load & verify data"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data loaded.\n",
            "Test data loaded.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from utils import load_nyt_data\n",
        "\n",
        "train_articles, train_labels_lists, test_articles, test_labels_lists = load_nyt_data()\n",
        "\n",
        "del train_articles\n",
        "del train_labels_lists\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test articles: 144279\n"
          ]
        }
      ],
      "source": [
        "print('Test articles:', len(test_articles))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dir = Path('../../../data/')\n",
        "gpt2_dir = Path('../GPT')\n",
        "\n",
        "ensemble_dir = data_dir / 'ensemble' / 'test'\n",
        "gpt2large_dir = gpt2_dir / 'large'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOKl3tDudyhU"
      },
      "source": [
        "# ensemble chunks are:\n",
        "# - non-shuffled\n",
        "# - non-filtered\n",
        "# - non-cutoff\n",
        "# - with transformed paths\n",
        "ensemble_file_paths = os.listdir(ensemble_dir)\n",
        "sorted_ensemble_filenames = sorted(ensemble_file_paths, key=lambda fn: int(fn.split('chunk')[1].split('of')[0]))\n",
        "sorted_ensemble_filepaths = [ensemble_dir / Path(p) for p in sorted_ensemble_filenames]\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxaAq4SJTmmZ"
      },
      "source": [
        "# gpt2-large chunks are\n",
        "# - seed-42-shuffled\n",
        "# - non-filtered\n",
        "# - non-cutoff\n",
        "# - with transformed labels\n",
        "gpt_file_paths = os.listdir(gpt2large_dir)\n",
        "sorted_gpt_filenames = sorted(gpt_file_paths, key=lambda fn: int(fn.split('chunk')[1].split('of')[0]))\n",
        "sorted_gpt_filepaths = [gpt2large_dir / Path(p) for p in sorted_gpt_filenames]\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 3 chunks\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8908a879c9984151ae65cffe635ac2f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded all chunks. Total length: 144279.\n"
          ]
        }
      ],
      "source": [
        "ensemble_dataset = ChunkMixDataset(sorted_ensemble_filepaths)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 2 chunks\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e31a8599ab7242069e9132e19801a9e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded all chunks. Total length: 144279.\n"
          ]
        }
      ],
      "source": [
        "gpt2large_dataset = ChunkMixDataset(sorted_gpt_filepaths)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ensemble chunks\n",
        "## verify non-filtered\n",
        "assert len(ensemble_dataset.y) == len(test_labels_lists)\n",
        "\n",
        "## verify non-shuffled\n",
        "for label_set_ensemble, label_set_raw in zip(ensemble_dataset.y, test_labels_lists):\n",
        "    assert set(label_set_ensemble) == set(label_set_raw), (label_set_ensemble, label_set_raw)\n",
        "\n",
        "# gpt2-large chunks\n",
        "## verify non-filtered\n",
        "assert len(gpt2large_dataset.y) == len(test_labels_lists)\n",
        "\n",
        "## verify seed-42-shuffled\n",
        "shuffled_test_labels_lists = test_labels_lists.copy()\n",
        "random.Random(42).shuffle(shuffled_test_labels_lists)\n",
        "for label_set_gpt2large, label_set_raw in zip(gpt2large_dataset.y, shuffled_test_labels_lists):\n",
        "    assert set(label_set_gpt2large) == set(label_set_raw), (label_set_gpt2large, label_set_raw)"
      ]
    },
    {
      "source": [
        "# Align & Filter"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# align\n",
        "random.Random(42).shuffle(ensemble_dataset.X)\n",
        "random.Random(42).shuffle(ensemble_dataset.y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teset articles after filtering: 133032\n"
          ]
        }
      ],
      "source": [
        "# filter\n",
        "min_len = 500\n",
        "\n",
        "shuffled_test_articles = test_articles.copy()\n",
        "random.Random(42).shuffle(shuffled_test_articles)\n",
        "\n",
        "filtered_test_indices = [i for i, article in enumerate(shuffled_test_articles) if len(article) >= min_len]\n",
        "\n",
        "ensemble_dataset.X = torch.vstack([ensemble_dataset.X[i] for i in filtered_test_indices])\n",
        "ensemble_dataset.y = [ensemble_dataset.y[i] for i in filtered_test_indices]\n",
        "\n",
        "gpt2large_dataset.X = torch.vstack([gpt2large_dataset.X[i] for i in filtered_test_indices])\n",
        "gpt2large_dataset.y = [gpt2large_dataset.y[i] for i in filtered_test_indices]\n",
        "\n",
        "print('Teset articles after filtering:', len(ensemble_dataset.X))"
      ]
    },
    {
      "source": [
        "# Verify"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# verify alignment\n",
        "\n",
        "for label_set_gpt2large, label_set_ensemble in zip(gpt2large_dataset.y, ensemble_dataset.y):\n",
        "    assert set(label_set_gpt2large) == set(label_set_ensemble), (label_set_gpt2large, label_set_ensemble)"
      ]
    },
    {
      "source": [
        "# Save"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "aligned_ensemble_dataset = EmbeddedDataset(ensemble_dataset.X, ensemble_dataset.y)\n",
        "aligned_gpt2large_dataset = EmbeddedDataset(gpt2large_dataset.X, gpt2large_dataset.y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "outdir = Path('/home/mbaliesnyi/code/nlp-project/data')\n",
        "\n",
        "ensemble_path = outdir / 'ensemble-aligned'\n",
        "gpt2large_path = outdir / 'single-gpt2-large-aligned'\n",
        "\n",
        "os.makedirs(ensemble_path / 'test' , exist_ok=True)\n",
        "os.makedirs(gpt2large_path / 'test' , exist_ok=True)\n",
        "\n",
        "torch.save(aligned_ensemble_dataset, ensemble_path / 'test' / 'aligned_filtered.pt')\n",
        "torch.save(aligned_gpt2large_dataset, gpt2large_path / 'test' / 'aligned_filtered.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 510M\ndrwxr-xr-x 2 mbaliesnyi users 4.0K Jun  5 13:38 .\ndrwxr-xr-x 4 mbaliesnyi users 4.0K Jun  5 13:38 ..\n-rw-r--r-- 1 mbaliesnyi users 510M Jun  5 13:38 aligned_filtered.pt\n"
          ]
        }
      ],
      "source": [
        "!ls -lah '{ensemble_path}/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 652M\ndrwxr-xr-x 2 mbaliesnyi users 4.0K Jun  5 13:38 .\ndrwxr-xr-x 4 mbaliesnyi users 4.0K Jun  5 13:38 ..\n-rw-r--r-- 1 mbaliesnyi users 652M Jun  5 13:38 aligned_filtered.pt\n"
          ]
        }
      ],
      "source": [
        "!ls -lah '{gpt2large_path}/test'"
      ]
    },
    {
      "source": [
        "# Move stuff to HPC"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aligned_filtered.pt                           100%  510MB  11.3MB/s   00:45    \n"
          ]
        }
      ],
      "source": [
        "!scp -r $ensemble_path/test hpc:/gpfs/space/projects/stud_nlp_share/ensemble-aligned/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aligned_filtered.pt                           100%  652MB  11.3MB/s   00:57    \n"
          ]
        }
      ],
      "source": [
        "!scp -r $gpt2large_path/test hpc:/gpfs/space/projects/stud_nlp_share/single-gpt2-large-aligned/"
      ]
    }
  ]
}